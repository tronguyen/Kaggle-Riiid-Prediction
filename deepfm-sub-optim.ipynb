{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fd8ff387-9c14-47ff-955d-d0bd1fd9b10d",
    "_uuid": "8554fa27-784e-4f25-b627-fdaf4f3dd959"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datatable as dt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "import gc\n",
    "import h5py\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fbf87edc-04b9-435e-80f1-d6554c756d73",
    "_uuid": "53e8bc27-466e-47ab-9591-c8ffcd0d871c"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c8848800-3d8b-4aa7-b0c5-e807ee7efd20",
    "_uuid": "cd990caf-b201-4f01-b7d5-77abb022832e"
   },
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        \n",
    "    def update(self, **kargs):\n",
    "        self.__dict__.update(kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "29a04d21-8112-44d0-827d-989ea07596ad",
    "_uuid": "45665757-b2d9-483e-8c2a-9dffbc5c54e6"
   },
   "outputs": [],
   "source": [
    "path = './kaggle/input/riiid-test-answer-prediction'\n",
    "train_file = f'{path}/train.csv'\n",
    "train_dtypes = {'row_id': 'int64',\n",
    "              'timestamp': 'int64',\n",
    "              'user_id': 'int32',\n",
    "              'content_id': 'int16',\n",
    "              'content_type_id': 'int8',\n",
    "              'task_container_id': 'int16',\n",
    "              'user_answer': 'int8',\n",
    "              'answered_correctly': 'int8',\n",
    "              'prior_question_elapsed_time': 'float32', \n",
    "              'prior_question_had_explanation': 'boolean',\n",
    "             }\n",
    "\n",
    "questions = pd.read_csv(f'{path}/questions.csv')\n",
    "lectures = pd.read_csv(f'{path}/lectures.csv')\n",
    "print('Question shapes:', questions.shape)\n",
    "print('Lecture shapes:', lectures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id', 'task_container_id', 'user_answer', 'answered_correctly', 'prior_question_elapsed_time', 'prior_question_had_explanation']\n",
    "# chunks = pd.read_csv(train_file, chunksize=1e3, dtype=train_dtypes, header=None, names=colnames, index_col=False)\n",
    "chunks = pd.read_csv(train_file, chunksize=1e6, dtype=train_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3bbb0f25-3253-480b-a4e3-8ab9adf15b7b",
    "_uuid": "fd79f190-cdc1-4284-b283-36814a278f03"
   },
   "outputs": [],
   "source": [
    "question_tags = list(map(lambda x: map(lambda v: int(v) + 1, str(x).split()) if str(x).strip() != 'nan' else [0], questions.tags.values))\n",
    "question_tags = list(set(itertools.chain(*question_tags)))\n",
    "\n",
    "n_tags = len(question_tags)\n",
    "n_parts = len(set(questions.part.unique()))\n",
    "\n",
    "print(f'n_tags {n_tags}, n_parts {n_parts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2408117-b91d-4c63-aa61-687b7228e13a",
    "_uuid": "e4c605ce-e959-4234-9b30-9f5f6d95fa5f"
   },
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    'load_state': True,\n",
    "    'use_buffer': True,\n",
    "    'is_offline': False,\n",
    "    'batch_norm': False,\n",
    "    'is_test': False,\n",
    "    'n_chunks': 10,\n",
    "    'n_epoch': 1,\n",
    "    'learning_rate': 3e-3,\n",
    "    'batch_size': 256,\n",
    "    'num_workers': 4,\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'num_questions': questions.question_id.nunique(),\n",
    "    'num_lectures': lectures.lecture_id.nunique(),\n",
    "    'num_total_q_tags': n_tags,\n",
    "    'num_total_q_part': n_parts,\n",
    "    'dropout': 0.1,\n",
    "    'fm_n_layers': 1,\n",
    "    'fm_h_size': 32,\n",
    "    'emb_size': 64,\n",
    "    'sparse_size': 8,\n",
    "    'dnn_n_layers': 4,\n",
    "    'dnn_h_size': 64,\n",
    "    'input_size': 512,\n",
    "    'buffer_size_limit': 1e3,\n",
    "    'limit_f1': 10, #lec-ques\n",
    "    'limit_f2': 5, # part\n",
    "    'limit_f3': 5, # tag\n",
    "    'limit_f4': 5, # user\n",
    "    'n_features': 8,\n",
    "    'output_dir': '/kaggle/working/data',\n",
    "    'extra_dir':'/kaggle/input/deepfm-input'\n",
    "}\n",
    "params = Params(**params_dict)\n",
    "print(params.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_part, n_tail=10):\n",
    "    valid = train_part.groupby('user_id').tail(n_tail)\n",
    "    train = train_part[~train_part.index.isin(valid.index)]\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LectureData(Dataset):\n",
    "    \n",
    "    def __init__(self, params, train_df=None, question_df=None, lecture_df=None, is_train=True):\n",
    "        # read init-data\n",
    "        self.params = params\n",
    "        self.is_train = is_train\n",
    "\n",
    "        self.scaler_ans_correct_mean = StandardScaler()\n",
    "        self.scaler_ans_correct_count = StandardScaler()\n",
    "        self.scaler_prior_question_time_mean = StandardScaler()\n",
    "        self.scaler_prior_question_elapsed_time = StandardScaler()\n",
    "#         self.scaler_timestamp = MinMaxScaler()\n",
    "\n",
    "        self.user_columns = ['user_id', 'ans_correct_sum', 'ans_correct_mean', 'ans_correct_count', 'lecture_set', 'lecture_tags_set', \n",
    "                             'prior_question_time_mean']\n",
    "\n",
    "        self.train_columns = ['user_id', 'content_id', 'content_type_id', 'task_container_id',\n",
    "                              'answered_correctly', 'prior_question_elapsed_time', 'prior_question_had_explanation']\n",
    "        \n",
    "        self.merge_columns = ['user_id', 'question_id', 'question_index', 'answered_correctly', 'ans_correct_mean', 'ans_correct_count',\n",
    "                              'part', 'tags_set', 'prior_question_time_mean', 'task_ans_correct_mean',\n",
    "                              'question_ans_correct_mean', 'question_ans_correct_count',\n",
    "                              'lecture_question_correct_mean', 'user_question_part_scores_mean', 'user_question_tag_scores_mean',\n",
    "                              'prior_question_had_explanation', 'prior_question_elapsed_time']\n",
    "        \n",
    "        self.prior_batch, self.current_batch, self.buffer_df, self.merge_df = None, None, None, None\n",
    "        self.user2idx, self.question2idx, self.lecture2idx = None, None, None\n",
    "        \n",
    "        # Restore all data\n",
    "        if params.load_state:\n",
    "            self.load_state()\n",
    "        else:\n",
    "            self.set_traindata(train_df, question_df, lecture_df)\n",
    "        \n",
    "    def proc_traindata(self, train_df):\n",
    "        \n",
    "        train_df['prior_question_elapsed_time'].fillna(0., inplace=True)\n",
    "        train_df['prior_question_had_explanation'].fillna(False, inplace=True)\n",
    "        train_df.loc[:, 'prior_question_had_explanation'] = train_df['prior_question_had_explanation'].astype(int)        \n",
    "        train_df.loc[:, 'prior_question_elapsed_time'] = train_df['prior_question_elapsed_time'].map(lambda x: np.log(x + 1.))\n",
    "#         train_df.loc[:, 'user_index'] = train_df['user_id'].apply(lambda x: self.user2idx[x])\n",
    "\n",
    "        return train_df\n",
    "    \n",
    "    def proc_questiondata(self, question_df):\n",
    "        \n",
    "        question_df.tags.fillna('-1', inplace=True)\n",
    "        question_df.loc[:, 'question_index'] = question_df['question_id'].map(lambda x: self.question2idx[x])\n",
    "        question_df['tags_set'] = question_df['tags'].map(lambda x: list(map(lambda s: int(s) + 1, str(x).split())))\n",
    "        question_df['part'] = question_df['part'].map(lambda x: x - 1)\n",
    "\n",
    "        return question_df\n",
    "        \n",
    "    def proc_lecturedata(self, lecture_df):\n",
    "        \n",
    "        lecture_df['lecture_index'] = lecture_df['lecture_id'].map(lambda x: self.lecture2idx[x])\n",
    "        lecture_df['lecture_id'] = lecture_df['lecture_id'].astype(int)\n",
    "\n",
    "        return lecture_df\n",
    "    \n",
    "    def load_state(self):\n",
    "        \n",
    "        self.user_df = pd.read_parquet(os.path.join(self.params.extra_dir,'user_df.gzip'))\n",
    "        self.question_df = pd.read_parquet(os.path.join(self.params.extra_dir,'question_df.gzip'))\n",
    "        self.lecture_df = pd.read_parquet(os.path.join(self.params.extra_dir,'lecture_df.gzip'))\n",
    "        \n",
    "        self.lecture_question_scores = pd.read_parquet(os.path.join(self.params.extra_dir,'lecture_question_scores.gzip'))\n",
    "        self.user_question_tag_scores = pd.read_parquet(os.path.join(self.params.extra_dir,'user_question_tag_scores.gzip'))\n",
    "        self.user_question_part_scores = pd.read_parquet(os.path.join(self.params.extra_dir,'user_question_part_scores.gzip'))\n",
    "        \n",
    "        self.user_df = self.user_df.set_index('user_id')\n",
    "        self.lecture_question_scores = self.lecture_question_scores.set_index(['question_id', 'lecture_id'])\n",
    "        self.user_question_tag_scores = self.user_question_tag_scores.set_index(['user_id', 'tag_id'])\n",
    "        self.user_question_part_scores = self.user_question_part_scores.set_index(['user_id', 'part'])\n",
    "        self.question_df = self.question_df.set_index('question_id')\n",
    "        self.lecture_df = self.lecture_df.set_index('lecture_id')\n",
    "        \n",
    "        f = h5py.File(os.path.join(self.params.extra_dir, 'data2idx.h5'), 'r')\n",
    "        self.user2idx = f['user2idx'][:]\n",
    "        self.n_users = len(self.user2idx)\n",
    "        self.user2idx = dict(zip(self.user2idx, range(self.n_users)))\n",
    "        \n",
    "        self.question2idx = f['question2idx'][:]\n",
    "        self.n_questions = len(self.question2idx)\n",
    "        self.question2idx = dict(zip(self.question2idx, range(self.n_questions)))\n",
    "        \n",
    "        self.lecture2idx = f['lecture2idx'][:]\n",
    "        self.n_lectures = len(self.lecture2idx)\n",
    "        self.lecture2idx = dict(zip(self.lecture2idx, range(self.n_lectures)))\n",
    "        f.close()\n",
    "        \n",
    "        self.scaler_ans_correct_count = joblib.load(os.path.join(self.params.extra_dir, 'scaler_ans_correct_count.save')) \n",
    "        self.scaler_prior_question_elapsed_time = joblib.load(os.path.join(self.params.extra_dir, 'scaler_prior_question_elapsed_time.save')) \n",
    "    \n",
    "    def init_info(self, train_df, question_df, lecture_df):\n",
    "        \n",
    "        self.user_list = list(train_df['user_id'].unique())\n",
    "        self.question_list = list(question_df['question_id'].unique())\n",
    "        self.lecture_list = list(lecture_df['lecture_id'].unique())\n",
    "\n",
    "        self.n_users = len(self.user_list)\n",
    "        self.n_questions = len(self.question_list)\n",
    "        self.n_lectures = len(self.lecture_list)\n",
    "        \n",
    "        self.user2idx = dict(zip(self.user_list, range(self.n_users)))\n",
    "        self.question2idx = dict(zip(self.question_list, range(self.n_questions)))\n",
    "        self.lecture2idx = dict(zip(self.lecture_list, range(self.n_lectures)))\n",
    "        \n",
    "    def fit_scaler(self, user_df):\n",
    "        \n",
    "        self.scaler_ans_correct_count.partial_fit(np.expand_dims(user_df['ans_correct_count'].values, 1))\n",
    "        self.scaler_prior_question_time_mean.partial_fit(np.expand_dims(user_df['prior_question_time_mean'].values, 1))\n",
    "        \n",
    "        \n",
    "    def transform_scaler(self, user_df):\n",
    "                \n",
    "        user_df['prior_question_elapsed_time'] = \\\n",
    "            self.scaler_prior_question_elapsed_time.transform(np.expand_dims(user_df['prior_question_elapsed_time'].values, 1)).squeeze(1)\n",
    "        \n",
    "#         user_df['timestamp'] = \\\n",
    "#             self.scaler_timestamp.transform(np.expand_dims(user_df['timestamp'].values, 1)).squeeze(1)\n",
    "\n",
    "        user_df['ans_correct_count'] = \\\n",
    "            self.scaler_ans_correct_count.transform(np.expand_dims(user_df['ans_correct_count'].values, 1)).squeeze(1)\n",
    "\n",
    "        user_df['prior_question_time_mean'] = \\\n",
    "            self.scaler_prior_question_time_mean.transform(np.expand_dims(user_df['prior_question_time_mean'].values, 1)).squeeze(1)\n",
    "        \n",
    "        return user_df\n",
    "\n",
    "    def feature_traindata(self, train_df):\n",
    "        \n",
    "        self.scaler_prior_question_elapsed_time.partial_fit(np.expand_dims(train_df['prior_question_elapsed_time'].values, 1))\n",
    "#         self.scaler_timestamp.partial_fit(np.expand_dims(train_df['timestamp'].values, 1))\n",
    "\n",
    "        grouped_by_task_id = train_df[train_df.content_type_id==0].groupby('task_container_id').agg({\n",
    "            'answered_correctly': ['sum', 'count', 'mean']\n",
    "        }).reset_index()\n",
    "        grouped_by_task_id.columns = ['task_container_id', 'task_ans_correct_sum', 'task_ans_correct_count', 'task_ans_correct_mean']\n",
    "        \n",
    "        return grouped_by_task_id\n",
    "\n",
    "    def feature_questiondata(self, train_df):\n",
    "        \n",
    "        question_train_df = train_df[train_df['content_type_id']==0]\n",
    "        \n",
    "        grouped_by_question = question_train_df.groupby('content_id').agg({\n",
    "            'answered_correctly': ['sum', 'count', 'mean']\n",
    "        }).reset_index() \n",
    "        grouped_by_question.columns = ['question_id', 'question_ans_correct_sum', 'question_ans_correct_count', 'question_ans_correct_mean']\n",
    "    \n",
    "        return grouped_by_question\n",
    "    \n",
    "    def feature_lecturedata(self, train_df):\n",
    "        \n",
    "        lecture_train_df = train_df[train_df['content_type_id']==1]\n",
    "        \n",
    "        grouped_by_lecture = lecture_train_df.groupby('content_id').agg({\n",
    "            'user_id': 'count'\n",
    "        }).reset_index()\n",
    "\n",
    "        grouped_by_lecture.columns = ['lecture_id', 'lecture_population']\n",
    "        \n",
    "        return grouped_by_lecture\n",
    "        \n",
    "    def feature_userdata(self, train_df):\n",
    "        \n",
    "        \n",
    "        # F: user ans correct mean \n",
    "        q_train_x = train_df[train_df['content_type_id']==0]        \n",
    "        q_train = q_train_x.merge(self.question_df, left_on='content_id', right_on='question_id', how='left', right_index=True)\n",
    "        question_grouped_by_user = q_train.groupby(['user_id']).agg({\n",
    "            'answered_correctly':['sum', 'count', 'mean'],\n",
    "            'prior_question_elapsed_time': 'mean',\n",
    "        }).reset_index()\n",
    "        question_grouped_by_user.columns = ['user_id', 'ans_correct_sum', 'ans_correct_count', 'ans_correct_mean',\n",
    "                                           'prior_question_time_mean']        \n",
    "        question_grouped_by_user.fillna(0, inplace=True)\n",
    "#         assert question_grouped_by_user.isnull().any().sum() == 0\n",
    "        \n",
    "        # new feature\n",
    "        user_question_part_scores = q_train.groupby(['user_id', 'part']).agg({\n",
    "            'answered_correctly': ['sum', 'count', 'mean']\n",
    "        }).reset_index()\n",
    "        user_question_part_scores.columns = ['user_id', 'part', 'user_question_part_scores_sum', \n",
    "                                             'user_question_part_scores_count', 'user_question_part_scores_mean']\n",
    "        user_question_part_scores['part'] = user_question_part_scores['part'].astype(int)\n",
    "        \n",
    "#         assert user_question_part_scores.isnull().any().sum() == 0\n",
    "        \n",
    "        # new feature\n",
    "        q_train_subset = q_train[['user_id', 'tags_set', 'answered_correctly']]\n",
    "        q_train_subset = q_train_subset.explode('tags_set')\n",
    "        q_train_subset.columns = ['user_id', 'tag_id', 'answered_correctly']\n",
    "        \n",
    "        user_question_tag_scores = q_train_subset.groupby(['user_id', 'tag_id']).agg({\n",
    "            'answered_correctly': ['sum', 'count', 'mean']\n",
    "        }).reset_index()\n",
    "        user_question_tag_scores.columns = ['user_id', 'tag_id', 'user_question_tag_scores_sum', \n",
    "                                            'user_question_tag_scores_count', 'user_question_tag_scores_mean']\n",
    "        user_question_tag_scores['tag_id'] = user_question_tag_scores['tag_id'].astype(int)\n",
    "                        \n",
    "#         assert user_question_tag_scores.isnull().any().sum() == 0\n",
    "        \n",
    "        l_train_x = train_df[train_df['content_type_id']==1]        \n",
    "        l_train = l_train_x.merge(self.lecture_df, left_on='content_id', right_on='lecture_id', how='left', right_index=True)\n",
    "        lecture_grouped_by_user = l_train.groupby(['user_id']).agg({\n",
    "            'lecture_id': lambda x: list(set(x)),\n",
    "            'tag': lambda x: list(set(x)),\n",
    "#             'part': lambda x: list(set(x)),\n",
    "#             'type_of': lambda x: list(set(x))\n",
    "        }).reset_index()\n",
    "\n",
    "        lecture_grouped_by_user.columns = ['user_id', 'lecture_set', 'lecture_tags_set']\n",
    "#                                           'lecture_part_set', 'lecture_typeof_set']\n",
    "        lecture_grouped_by_user.fillna(0, inplace=True)\n",
    "#         assert lecture_grouped_by_user.isnull().any().sum() == 0\n",
    "\n",
    "        # Gen user-feature\n",
    "        question_grouped_by_user = question_grouped_by_user.set_index('user_id')\n",
    "        lecture_grouped_by_user = lecture_grouped_by_user.set_index('user_id')\n",
    "        \n",
    "        user_df = question_grouped_by_user.join(lecture_grouped_by_user, on='user_id', how='outer').reset_index()\n",
    "        \n",
    "        if self.is_train:\n",
    "            self.fit_scaler(user_df)\n",
    "#             user_df = self.transform_scaler(user_df)\n",
    "                \n",
    "        # Get lecture-question scores\n",
    "        l_train = l_train_x[['user_id', 'content_id']]\n",
    "        l_train = l_train.rename(columns={'content_id': 'lecture_id'})\n",
    "        q_train = q_train_x[['user_id', 'content_id', 'answered_correctly']]\n",
    "        q_train = q_train.rename(columns={'content_id': 'question_id'})\n",
    "        \n",
    "        #optim        \n",
    "        lecture_question_scores = l_train.merge(q_train, on='user_id')\n",
    "        lecture_question_scores = lecture_question_scores.groupby(['lecture_id', 'question_id']).agg({\n",
    "            'answered_correctly': ['sum', 'count', 'mean']\n",
    "        }).reset_index()\n",
    "        lecture_question_scores.columns = ['lecture_id', 'question_id', \n",
    "                                           'lecture_question_correct_sum', 'lecture_question_correct_count', 'lecture_question_correct_mean']\n",
    "        lecture_question_scores['lecture_id'] = lecture_question_scores['lecture_id'].astype(int)\n",
    "        lecture_question_scores['question_id'] = lecture_question_scores['question_id'].astype(int)\n",
    "        \n",
    "#         assert lecture_question_scores.isnull().any().sum() == 0\n",
    "\n",
    "        # filter all NAN\n",
    "        user_df = user_df[self.user_columns]\n",
    "        \n",
    "#         user_df['tag_vec_score_sum'] = user_df['tag_vec_score_sum'].apply(lambda x: x if isinstance(x, list) else list(np.zeros(self.params.num_total_q_tags)))\n",
    "#         user_df['tag_vec_score_count'] = user_df['tag_vec_score_count'].apply(lambda x: x if isinstance(x, list) else list(np.zeros(self.params.num_total_q_tags)))\n",
    "        \n",
    "#         user_df['part_vec_score_sum'] = user_df['part_vec_score_sum'].apply(lambda x: x if isinstance(x, list) else list(np.zeros(self.params.num_total_q_part)))\n",
    "#         user_df['part_vec_score_count'] = user_df['part_vec_score_count'].apply(lambda x: x if isinstance(x, list) else list(np.zeros(self.params.num_total_q_part)))\n",
    "\n",
    "        user_df['lecture_set'] = user_df['lecture_set'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "        user_df['lecture_tags_set'] = user_df['lecture_tags_set'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "#         user_df['lecture_part_set'] = user_df['lecture_part_set'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "#         user_df['lecture_typeof_set'] = user_df['lecture_typeof_set'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "                             \n",
    "#         assert user_df.isnull().any().sum() == 0\n",
    "        \n",
    "        return (user_df, \n",
    "                lecture_question_scores, \n",
    "                user_question_part_scores, \n",
    "                user_question_tag_scores)\n",
    "    \n",
    "    def finalize_data(self, data_df):\n",
    "        # Filter out all\n",
    "        self.lecture_question_scores.loc[self.lecture_question_scores['lecture_question_correct_count'] < self.params.limit_f1, 'lecture_question_correct_mean'] = 0.5\n",
    "        self.user_question_part_scores.loc[self.user_question_part_scores['user_question_part_scores_count'] < self.params.limit_f2, 'user_question_part_scores_mean'] = 0.5\n",
    "        self.user_question_tag_scores.loc[self.user_question_tag_scores['user_question_tag_scores_count'] < self.params.limit_f3, 'user_question_tag_scores_mean'] = 0.5\n",
    "        self.user_df.loc[self.user_df['ans_correct_count'] < self.params.limit_f4, 'ans_correct_mean'] = 0.5\n",
    "\n",
    "        # Only filter content-type this step\n",
    "        data_df = data_df[data_df['content_type_id']==0]\n",
    "        data_df = data_df[self.train_columns]\n",
    "        data_df = data_df.rename(columns={'content_id': 'question_id'})\n",
    "       \n",
    "        # Get lectures\n",
    "        ql_df = data_df[['user_id', 'question_id']].set_index('user_id').join(self.user_df, on='user_id', how='left')\n",
    "        ql_df = ql_df.explode('lecture_set')\n",
    "        ql_df = ql_df.rename(columns={'lecture_set': 'lecture_id'})\n",
    "        ql_df.reset_index(inplace=True)\n",
    "        ql_df = ql_df.set_index(['question_id', 'lecture_id']).join(self.lecture_question_scores, on=['question_id', 'lecture_id'], how='left')\n",
    "        ql_df = ql_df.groupby(['user_id', 'question_id'])['lecture_question_correct_mean'].mean()\n",
    "        \n",
    "        # user-tags-scores\n",
    "        user_tags_df = data_df[['user_id', 'question_id']].set_index('question_id').join(self.question_df, on='question_id', how='left').reset_index()\n",
    "        user_tags_df = user_tags_df[['user_id', 'question_id', 'tags_set']]\n",
    "        user_tags_df = user_tags_df.explode('tags_set')\n",
    "        user_tags_df = user_tags_df.rename(columns={'tags_set': 'tag_id'})\n",
    "        user_tags_df = user_tags_df.set_index(['user_id', 'tag_id']).join(self.user_question_tag_scores, on=['user_id', 'tag_id'], how='left')\\\n",
    "                                   .groupby(['user_id', 'question_id'])['user_question_tag_scores_mean'].mean()\n",
    "        \n",
    "        # Final df\n",
    "        merge_df = data_df.join(ql_df, on=['user_id', 'question_id'], how='left')\\\n",
    "                          .join(user_tags_df, on=['user_id', 'question_id'], how='left')\\\n",
    "                          .join(self.question_df, on='question_id', how='left')\\\n",
    "                          .join(self.user_df, on='user_id', how='left')\\\n",
    "                          .join(self.user_question_part_scores, on=['user_id', 'part'], how='left')\\\n",
    "                          .join(self.task_df, on='task_container_id', how='left')\n",
    "                          \n",
    "        del data_df, ql_df, user_tags_df\n",
    "        merge_df = merge_df[self.merge_columns]\n",
    "\n",
    "        # scaler transform\n",
    "        merge_df = self.transform_scaler(merge_df)        \n",
    "        merge_df['ans_correct_mean'].fillna(0.65, inplace=True)\n",
    "        merge_df['ans_correct_count'].fillna(0., inplace=True)\n",
    "        merge_df['prior_question_time_mean'].fillna(0., inplace=True)\n",
    "        merge_df['question_ans_correct_mean'].fillna(0.5, inplace=True)\n",
    "        merge_df['lecture_question_correct_mean'].fillna(0.5, inplace=True)\n",
    "        merge_df['user_question_part_scores_mean'].fillna(0.5, inplace=True)\n",
    "        merge_df['user_question_tag_scores_mean'].fillna(0.5, inplace=True)\n",
    "        merge_df['task_ans_correct_mean'].fillna(0.5, inplace=True)\n",
    "        \n",
    "        merge_df['prior_question_elapsed_time'].fillna(0., inplace=True)\n",
    "        merge_df['prior_question_had_explanation'].fillna(0, inplace=True)\n",
    "        \n",
    "#         merge_df['timestamp'].fillna(0., inplace=True)\n",
    "#         merge_df['part'] = merge_df['part'].fillna(0).astype(int)\n",
    "#         merge_df['tags_set'] = merge_df['tags_set'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "        \n",
    "#         merge_df['tag_vec_score_count'] = merge_df['tag_vec_score_count'].apply(lambda x: x if isinstance(x, list) else list(np.zeros(self.params.num_total_q_tags)))\n",
    "#         merge_df['tag_vec_score_sum'] = merge_df['tag_vec_score_sum'].apply(lambda x: x if isinstance(x, list) else list(np.zeros(self.params.num_total_q_tags)))\n",
    "        \n",
    "#         merge_df['part_vec_score_count'] = merge_df['part_vec_score_count'].apply(lambda x: x if isinstance(x, list) else list(np.zeros(self.params.num_total_q_part)))\n",
    "#         merge_df['part_vec_score_sum'] = merge_df['part_vec_score_sum'].apply(lambda x: x if isinstance(x, list) else list(np.zeros(self.params.num_total_q_part)))\n",
    "        \n",
    "#         assert merge_df.isnull().any().sum() == 0\n",
    "        \n",
    "        return merge_df  \n",
    "    \n",
    "    def set_traindata(self, train_df, question_df, lecture_df):\n",
    "        # Fetch init info\n",
    "        self.init_info(train_df, question_df, lecture_df)\n",
    "        \n",
    "        # Refine all dfs\n",
    "        train_df = self.proc_traindata(train_df)\n",
    "        question_df = self.proc_questiondata(question_df)\n",
    "        lecture_df = self.proc_lecturedata(lecture_df)\n",
    "                \n",
    "        # Update all data\n",
    "        self.task_df = self.feature_traindata(train_df)\n",
    "        \n",
    "        question_stats_df = self.feature_questiondata(train_df)\n",
    "        question_stats_df.set_index('question_id', inplace=True)\n",
    "        question_df.set_index('question_id', inplace=True)\n",
    "        \n",
    "        self.question_df = question_df.merge(question_stats_df, on='question_id', how='left').reset_index()\n",
    "        self.question_df.fillna(0.5, inplace=True)\n",
    "#         assert self.question_df.isnull().any().sum() == 0, 'Question with NAN'\n",
    "        \n",
    "        lecture_stats_df = self.feature_lecturedata(train_df)\n",
    "        lecture_stats_df.set_index('lecture_id', inplace=True)\n",
    "        lecture_df.set_index('lecture_id', inplace=True)\n",
    "        \n",
    "        self.lecture_df = lecture_df.merge(lecture_stats_df, on='lecture_id', how='left').reset_index()\n",
    "        self.lecture_df.fillna(0., inplace=True)\n",
    "#         assert self.lecture_df.isnull().any().sum() == 0, 'Lecture with NAN'\n",
    "        \n",
    "        # update all question/lecture before user-df\n",
    "        (self.user_df, self.lecture_question_scores,\n",
    "            self.user_question_part_scores, self.user_question_tag_scores) = self.feature_userdata(train_df)\n",
    "        \n",
    "        # Fetch users w question only        \n",
    "        self.set_index()\n",
    "        self.merge_df = self.finalize_data(train_df)\n",
    "        \n",
    "    def update_newdata(self, batch_df, skip_stat=True):\n",
    "        \n",
    "        if skip_stat:\n",
    "            n_newusers, n_newquestions, n_newlectures = 0, 0, 0\n",
    "        else:\n",
    "            # fetch all new instances        \n",
    "            new_users = list(set(batch_df.user_id.unique()) - set(self.user2idx.keys()))\n",
    "            new_questions = list(set(batch_df.loc[batch_df['content_type_id']==0, 'content_id'].unique()) - set(self.question2idx.keys()))\n",
    "            new_lectures = list(set(batch_df.loc[batch_df['content_type_id']==1, 'content_id'].unique()) - set(self.lecture2idx.keys()))\n",
    "\n",
    "            n_newusers = len(new_users)\n",
    "            n_newquestions = len(new_questions)\n",
    "            n_newlectures = len(new_lectures)\n",
    "\n",
    "            new_user2idx = dict(zip(new_users, range(self.n_users, self.n_users + n_newusers)))\n",
    "            new_question2idx = dict(zip(new_questions, range(self.n_questions, self.n_questions + n_newquestions)))\n",
    "            new_lecture2idx = dict(zip(new_lectures, range(self.n_lectures, self.n_lectures + n_newlectures)))\n",
    "\n",
    "            self.user2idx.update(new_user2idx)\n",
    "            self.question2idx.update(new_question2idx)\n",
    "            self.lecture2idx.update(new_lecture2idx)\n",
    "\n",
    "            self.n_users = self.n_users + n_newusers\n",
    "            self.n_questions = self.n_questions + n_newquestions\n",
    "            self.n_lectures = self.n_lectures + n_newlectures\n",
    "        \n",
    "            # Append new questions + lectures\n",
    "            if n_newquestions > 0:\n",
    "                extra_questions = pd.DataFrame(list(new_question2idx.items()), \n",
    "                                               columns=['question_id', 'question_index'])\n",
    "                self.question_df = pd.concat([self.question_df, extra_questions], axis=0, ignore_index=True)\n",
    "\n",
    "            if n_newlectures > 0:\n",
    "                extra_lectures = pd.DataFrame(list(new_lecture2idx.items()), \n",
    "                                               columns=['lecture_id', 'lecture_index'])\n",
    "                self.lecture_df = pd.concat([self.lecture_df, extra_lectures], axis=0, ignore_index=True)\n",
    "            \n",
    "        # Add user-index\n",
    "        batch_df = self.proc_traindata(batch_df)                \n",
    "        return batch_df, n_newusers, n_newquestions, n_newlectures    \n",
    "    \n",
    "    def test_batch(self, batch_df):\n",
    "        # update new data\n",
    "        self.is_train = False\n",
    "        batch_df, n_newusers, n_newquestions, n_newlectures = self.update_newdata(batch_df)\n",
    "        \n",
    "        # fetch prior labels\n",
    "        gt_prior_batch = eval(batch_df.iloc[0][\"prior_group_answers_correct\"])\n",
    "        \n",
    "        # HERE stop updating first for 1st submission\n",
    "        if self.current_batch is not None and len(gt_prior_batch) > 0:\n",
    "            # save prior-batch with labels\n",
    "            self.prior_batch = self.current_batch\n",
    "            \n",
    "            # Assign label to prev-batch\n",
    "            self.prior_batch['answered_correctly'] = gt_prior_batch\n",
    "            self.prior_batch = self.prior_batch[self.train_columns]\n",
    "            \n",
    "            # add to buffer-df\n",
    "            if self.params.use_buffer:\n",
    "                self.buffer_df = pd.concat([self.buffer_df, self.prior_batch], axis=0, ignore_index=True)\n",
    "                del self.prior_batch\n",
    "             \n",
    "        else:\n",
    "            self.prior_batch = batch_df\n",
    "        \n",
    "        self.current_batch = batch_df\n",
    "        # create dummy labels\n",
    "        self.current_batch['answered_correctly'] = 0\n",
    "                            \n",
    "        # Update new-batch-data\n",
    "        self.merge_df = self.finalize_data(self.current_batch)       \n",
    "        \n",
    "        return n_newusers, n_newquestions, n_newlectures\n",
    "    \n",
    "    def set_batch(self, batch_df):\n",
    "        \n",
    "        self.is_train = True\n",
    "        batch_df, n_newusers, n_newquestions, n_newlectures = self.update_newdata(batch_df)\n",
    "        \n",
    "        # Update new-batch-data\n",
    "        self.merge_df = self.finalize_data(batch_df)    \n",
    "        return batch_df, n_newusers, n_newquestions, n_newlectures\n",
    "        \n",
    "    def finetune_batch(self):\n",
    "        \"\"\" Only finetune on previous batch-data with labels\n",
    "        \"\"\"\n",
    "        if self.buffer_df is not None and len(self.buffer_df) > params.buffer_size_limit:\n",
    "            print('--> Dataset activated finetune buffer')\n",
    "            self.is_train = True\n",
    "            \n",
    "            stat_buff, train_buff = split_data(self.buffer_df, n_tail=5)\n",
    "            self.agg_newdata(stat_buff)\n",
    "            self.merge_df = self.finalize_data(train_buff)\n",
    "            self.buffer_df = None\n",
    "        \n",
    "            # clean buffer\n",
    "            self.lecture_question_scores = self.lecture_question_scores.iloc[-100000:]\n",
    "            self.user_question_tag_scores = self.user_question_tag_scores.iloc[-100000:]\n",
    "            self.user_question_part_scores = self.user_question_part_scores.iloc[-100000:]\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def stats_data(self, train_df):\n",
    "        \n",
    "        # Fetch all local-stats\n",
    "        task_stats_df = self.feature_traindata(train_df)\n",
    "        question_stats_df = self.feature_questiondata(train_df)\n",
    "        lecture_stats_df = self.feature_lecturedata(train_df)\n",
    "        user_compound = self.feature_userdata(train_df)\n",
    "        \n",
    "        return train_df, question_stats_df, lecture_stats_df, task_stats_df, user_compound\n",
    "    \n",
    "    def reset_index(self):\n",
    "        \n",
    "        self.user_df = self.user_df.reset_index()\n",
    "        self.lecture_question_scores = self.lecture_question_scores.reset_index()\n",
    "        self.user_question_tag_scores = self.user_question_tag_scores.reset_index()\n",
    "        self.user_question_part_scores = self.user_question_part_scores.reset_index()\n",
    "        self.question_df = self.question_df.reset_index()\n",
    "        self.lecture_df = self.lecture_df.reset_index()\n",
    "        self.task_df = self.task_df.reset_index()\n",
    "        \n",
    "    def set_index(self):\n",
    "        \n",
    "        self.user_df = self.user_df.set_index('user_id')\n",
    "        self.lecture_question_scores = self.lecture_question_scores.set_index(['question_id', 'lecture_id'])\n",
    "        self.user_question_tag_scores = self.user_question_tag_scores.set_index(['user_id', 'tag_id'])\n",
    "        self.user_question_part_scores = self.user_question_part_scores.set_index(['user_id', 'part'])\n",
    "        self.question_df = self.question_df.set_index('question_id')\n",
    "        self.lecture_df = self.lecture_df.set_index('lecture_id')\n",
    "        self.task_df = self.task_df.set_index('task_container_id')\n",
    "\n",
    "    def agg_newdata(self, train_df, is_finetune=False):\n",
    "        self.reset_index()\n",
    "        # update info new-data\n",
    "        self.is_train = True\n",
    "        if is_finetune:\n",
    "            n_newusers, n_newquestions, n_newlectures = 0, 0, 0\n",
    "        else:\n",
    "            train_df, n_newusers, n_newquestions, n_newlectures = self.update_newdata(train_df)\n",
    "        \n",
    "        # run stats on new-data\n",
    "        train_df, question_stats_df, lecture_stats_df, task_stats_df, user_compound = self.stats_data(train_df)\n",
    "        new_user_df, new_lecture_question_scores, new_user_question_part_scores, new_user_question_tag_scores = user_compound\n",
    "        \n",
    "        self.task_df = pd.concat([self.task_df, task_stats_df], axis=0, ignore_index=True)\n",
    "        self.task_df = self.task_df.groupby('task_container_id').agg({\n",
    "            'task_ans_correct_sum': 'sum',\n",
    "            'task_ans_correct_count': 'sum'\n",
    "        }).reset_index()\n",
    "        self.task_df['task_ans_correct_mean'] = self.task_df['task_ans_correct_sum'] / self.task_df['task_ans_correct_count']\n",
    "        \n",
    "        self.user_df = pd.concat([self.user_df, new_user_df], axis=0, ignore_index=True)\n",
    "        self.user_df = self.user_df.groupby('user_id').agg({\n",
    "            'ans_correct_sum': 'sum',\n",
    "            'ans_correct_count': 'sum',\n",
    "            'prior_question_time_mean': 'mean',\n",
    "            'lecture_set': lambda x: list(set(itertools.chain(*x))),\n",
    "            'lecture_tags_set': lambda x: list(set(itertools.chain(*x))),\n",
    "#             'lecture_part_set': lambda x: list(set(itertools.chain(*x))),\n",
    "#             'lecture_typeof_set': lambda x: list(set(itertools.chain(*x))),\n",
    "#             'tag_vec_score_sum': lambda x: list(np.sum(np.array([*x]), 0)),\n",
    "#             'tag_vec_score_count': lambda x: list(np.sum(np.array([*x]), 0)),\n",
    "#             'part_vec_score_sum': lambda x: list(np.sum(np.array([*x]), 0)),\n",
    "#             'part_vec_score_count': lambda x: list(np.sum(np.array([*x]), 0)),\n",
    "        }).reset_index()\n",
    "#         pdb.set_trace()\n",
    "        self.user_df['ans_correct_mean'] = self.user_df['ans_correct_sum'] / self.user_df['ans_correct_count']\n",
    "                \n",
    "        self.lecture_question_scores = pd.concat([self.lecture_question_scores, \n",
    "                                                  new_lecture_question_scores], axis=0, ignore_index=True)\n",
    "        self.lecture_question_scores = self.lecture_question_scores.groupby(['lecture_id', 'question_id']).agg({\n",
    "            'lecture_question_correct_sum': 'sum',\n",
    "            'lecture_question_correct_count': 'sum',\n",
    "        }).reset_index()\n",
    "        \n",
    "        self.lecture_question_scores['lecture_question_correct_mean'] = self.lecture_question_scores['lecture_question_correct_sum'] / self.lecture_question_scores['lecture_question_correct_count']\n",
    "\n",
    "#         assert self.lecture_question_scores.isnull().any().sum() == 0\n",
    "        \n",
    "        self.user_question_part_scores = pd.concat([self.user_question_part_scores, \n",
    "                                                  new_user_question_part_scores], axis=0, ignore_index=True)\n",
    "        self.user_question_part_scores = self.user_question_part_scores.groupby(['user_id', 'part']).agg({\n",
    "            'user_question_part_scores_sum': 'sum',\n",
    "            'user_question_part_scores_count': 'sum',\n",
    "        }).reset_index()\n",
    "        self.user_question_part_scores['user_question_part_scores_mean'] = self.user_question_part_scores['user_question_part_scores_sum'] / self.user_question_part_scores['user_question_part_scores_count']\n",
    "        \n",
    "#         assert self.user_question_part_scores.isnull().any().sum() == 0\n",
    "        \n",
    "        self.user_question_tag_scores = pd.concat([self.user_question_tag_scores, \n",
    "                                                  new_user_question_tag_scores], axis=0, ignore_index=True)\n",
    "        self.user_question_tag_scores = self.user_question_tag_scores.groupby(['user_id', 'tag_id']).agg({\n",
    "            'user_question_tag_scores_sum': 'sum',\n",
    "            'user_question_tag_scores_count': 'sum',\n",
    "        }).reset_index()\n",
    "        self.user_question_tag_scores['user_question_tag_scores_mean'] = self.user_question_tag_scores['user_question_tag_scores_sum'] / self.user_question_tag_scores['user_question_tag_scores_count']        \n",
    "#         assert self.user_question_tag_scores.isnull().any().sum() == 0\n",
    "        \n",
    "        # update question-part\n",
    "        subset = self.question_df.loc[self.question_df['question_id'].isin(question_stats_df['question_id'].values), :].copy()\n",
    "        subset = subset.merge(question_stats_df, on='question_id', how='left')\n",
    "        subset['question_ans_correct_sum'] = subset[['question_ans_correct_sum_x','question_ans_correct_sum_y']].sum(axis=1)\n",
    "        subset['question_ans_correct_count'] = subset[['question_ans_correct_count_x','question_ans_correct_count_y']].sum(axis=1)        \n",
    "        subset['question_ans_correct_mean'] = subset['question_ans_correct_sum'] / subset['question_ans_correct_count']\n",
    "\n",
    "        self.question_df.loc[self.question_df['question_id'].isin(question_stats_df['question_id'].values), \n",
    "                             'question_ans_correct_mean'] = subset['question_ans_correct_mean'].values\n",
    "        self.question_df.loc[self.question_df['question_id'].isin(question_stats_df['question_id'].values), \n",
    "                             'question_ans_correct_count'] = subset['question_ans_correct_count'].values\n",
    "        self.question_df.loc[self.question_df['question_id'].isin(question_stats_df['question_id'].values), \n",
    "                             'question_ans_correct_sum'] = subset['question_ans_correct_sum'].values\n",
    "        \n",
    "        del subset, question_stats_df, lecture_stats_df\n",
    "        del new_lecture_question_scores, new_user_question_part_scores, new_user_question_tag_scores\n",
    "        # update lecture-part\n",
    "        \n",
    "        # Update new data for training\n",
    "        self.set_index()\n",
    "        \n",
    "        return n_newusers, n_newquestions, n_newlectures\n",
    "    \n",
    "    def cleanup(self):\n",
    "        print('--> Dataset cleaning ...')\n",
    "        if self.buffer_df is not None:\n",
    "            del self.buffer_df\n",
    "            self.buffer_df = None\n",
    "        if self.merge_df is not None:\n",
    "            del self.merge_df\n",
    "            self.merge_df = None\n",
    "        gc.collect()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.merge_df.shape[0] if self.merge_df is not None else 0\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ins = self.merge_df.iloc[index]\n",
    "        target = ins['answered_correctly']\n",
    "        \n",
    "        # get user-info\n",
    "#         user_id = ins['user_index']\n",
    "        user_ans_correct_mean = ins['ans_correct_mean']\n",
    "        user_ans_correct_count = ins['ans_correct_count'] \n",
    "        user_prior_question_time_mean = ins['prior_question_time_mean']\n",
    "        user_prior_question_elapsed_time = ins['prior_question_elapsed_time']\n",
    "        user_prior_question_had_explanation = ins['prior_question_had_explanation']\n",
    "        \n",
    "        # user-item interaction\n",
    "        user_item_correct_score = ins['lecture_question_correct_mean']\n",
    "        user_tag_correct_score = ins['user_question_tag_scores_mean']\n",
    "        user_part_correct_score = ins['user_question_part_scores_mean']\n",
    "        user_task_ans_correct = ins['task_ans_correct_mean']\n",
    "                \n",
    "        # item/question-info\n",
    "#         item_id = ins['question_index']\n",
    "#         item_part_vec = np.zeros(self.params.num_total_q_part)\n",
    "#         item_part_vec[list([ins['part']])] = 1.\n",
    "#         item_part = item_part_vec\n",
    "        \n",
    "#         item_tags_vec = np.zeros(self.params.num_total_q_tags)\n",
    "#         item_tags_vec[list(ins['tags_set'])] = 1.\n",
    "#         item_tags = item_tags_vec\n",
    "        item_ans_correct_mean = ins['question_ans_correct_mean']\n",
    "        \n",
    "        return (torch.FloatTensor([user_task_ans_correct]),\n",
    "                torch.FloatTensor([user_item_correct_score]), \n",
    "                torch.FloatTensor([user_ans_correct_mean]), \n",
    "                torch.FloatTensor([user_ans_correct_count]),\n",
    "                torch.FloatTensor([user_prior_question_time_mean]),\n",
    "                torch.FloatTensor([user_tag_correct_score]),\n",
    "                torch.FloatTensor([user_part_correct_score]),\n",
    "                torch.FloatTensor([user_prior_question_elapsed_time]),\n",
    "                torch.FloatTensor([user_prior_question_had_explanation]),\n",
    "                torch.FloatTensor([item_ans_correct_mean]),\n",
    "                torch.FloatTensor([target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7634bd95-45a1-4dd2-8c7b-01247a9f8d36",
    "_uuid": "f7bd1d3f-a115-46b5-9954-168645ea6335"
   },
   "outputs": [],
   "source": [
    "class FM_COMP(nn.Module):\n",
    "    def __init__(self, n_layers, h_size, emb_size, sparse_size, n_features, dropout=0.0, batch_norm=False):\n",
    "        super(FM_COMP, self).__init__()\n",
    "        self.batch_norm = batch_norm\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        if batch_norm:\n",
    "            self.bnorm = nn.BatchNorm1d(h_size)\n",
    "            self.bn = nn.BatchNorm1d(emb_size)\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.score = nn.Linear(h_size, 1)\n",
    "        \n",
    "        _in_size = emb_size\n",
    "        for i in range(n_layers):\n",
    "            _out_size = h_size * (n_layers - i)\n",
    "            self.layers.append(nn.Linear(_in_size, _out_size))\n",
    "            _in_size = _out_size\n",
    "            \n",
    "        self.sparse_layer = nn.Linear(sparse_size, 1)\n",
    "\n",
    "#         self.combine_layer = nn.Linear(1 + n_features**2, 1)\n",
    "        \n",
    "    def forward(self, x, sp_f):\n",
    "        \n",
    "        # bi-pooling part\n",
    "        summed_feature_emb = torch.sum(x, dim=1) # [None, K]\n",
    "        summed_squared_faeture_emb = torch.square(summed_feature_emb) # [None, K]\n",
    "        \n",
    "        square_feature_emb = torch.square(x) # [None, F, K]\n",
    "        squared_summed_feature_emb = torch.sum(square_feature_emb, dim=1)\n",
    "        bi_pool = 0.5 * (summed_squared_faeture_emb - squared_summed_feature_emb) # [None, K]\n",
    "        \n",
    "        if self.batch_norm:\n",
    "            bi_pool = self.bn(bi_pool)\n",
    "        bi_pool = self.dropout(bi_pool)\n",
    "        \n",
    "        for i, h_layer in enumerate(self.layers):\n",
    "            bi_pool = h_layer(bi_pool)       \n",
    "            if self.batch_norm:\n",
    "                bi_pool = self.bnorm(bi_pool)\n",
    "            bi_pool = F.relu(bi_pool)\n",
    "            bi_pool = self.dropout(bi_pool)\n",
    "        \n",
    "        bi_pool = self.score(bi_pool)\n",
    "        \n",
    "#         x_norm = F.normalize(x, p=2, dim=-1)\n",
    "#         x_fm = torch.matmul(x_norm, x_norm.permute(0, 2, 1)) # [None, F, F]\n",
    "#         x_fm = torch.triu(x_fm, diagonal=1)\n",
    "#         x_fm = x_fm.reshape(-1, x.shape[1]**2)\n",
    "#         combine = torch.cat([x_fm, sparse_out], dim=-1)\n",
    "#         out = self.combine_layer(combine)\n",
    "        \n",
    "        # sparse-feature part\n",
    "        sparse_out = self.sparse_layer(sp_f)\n",
    "        out = bi_pool + sparse_out\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "29c72cc1-1413-4bfe-8192-53aeea034815",
    "_uuid": "cadd3ad3-cf48-406b-9624-d94e7c824c7a"
   },
   "outputs": [],
   "source": [
    "class DNN_COMP(nn.Module):\n",
    "    def __init__(self, n_layers, h_size, input_size, dropout=0.0, batch_norm=False):\n",
    "        super(DNN_COMP, self).__init__()\n",
    "        self.batch_norm = batch_norm\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if batch_norm:\n",
    "            self.bnorm = nn.BatchNorm1d(h_size)\n",
    "        self.score = nn.Linear(h_size, 1)\n",
    "        \n",
    "        _in_size = input_size\n",
    "        for i in range(n_layers):\n",
    "            _out_size = h_size * (n_layers - i)\n",
    "            self.layers.append(nn.Linear(_in_size, _out_size))\n",
    "            _in_size = _out_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, h_layer in enumerate(self.layers):\n",
    "            x = h_layer(x)            \n",
    "            if self.batch_norm:\n",
    "                x = self.bnorm(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        out = self.score(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4b8f4c81-2937-405a-9ff1-baf7038a020c",
    "_uuid": "aabb5f8b-8357-47ed-971b-4576e3e65964"
   },
   "outputs": [],
   "source": [
    "class DEEPFM(nn.Module):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        super(DEEPFM, self).__init__()\n",
    "        self.params = params\n",
    "        self.fm_comp = FM_COMP(params.fm_n_layers, \n",
    "                               params.fm_h_size, \n",
    "                               params.emb_size, \n",
    "                               params.sparse_size, \n",
    "                               params.n_features,\n",
    "                               dropout=params.dropout,\n",
    "                               batch_norm=params.batch_norm)\n",
    "        \n",
    "        self.dnn_comp = DNN_COMP(params.dnn_n_layers, \n",
    "                                 params.dnn_h_size, \n",
    "                                 params.input_size, \n",
    "                                 dropout=params.dropout,\n",
    "                                 batch_norm=params.batch_norm)\n",
    "        \n",
    "#         self.user_emb = nn.Embedding(params.num_users, params.emb_size)\n",
    "#         self.question_emb = nn.Embedding(params.num_questions, params.emb_size)\n",
    "        \n",
    "        self.ans_mean = nn.Linear(1, params.emb_size, bias=False)\n",
    "        self.ans_count = nn.Linear(1, params.emb_size, bias=False)\n",
    "                \n",
    "        self.prior_time_mean = nn.Linear(1, params.emb_size, bias=False)\n",
    "        self.question_correct_emb = nn.Linear(1, params.emb_size, bias=False)\n",
    "        \n",
    "        self.user_question_correct_emb = nn.Linear(1, params.emb_size, bias=False)\n",
    "        self.user_tag_correct_emb = nn.Linear(1, params.emb_size, bias=False)\n",
    "        self.user_part_correct_emb = nn.Linear(1, params.emb_size, bias=False)\n",
    "        self.task_ans_correct_emb = nn.Linear(1, params.emb_size, bias=False)\n",
    "        \n",
    "        self.prior_time = nn.Linear(1, params.emb_size, bias=False)\n",
    "        self.prior_question_explained = nn.Linear(1, params.emb_size, bias=False)\n",
    "        \n",
    "    def update_size(self, n_users, n_questions, n_lectures):\n",
    "        # add new users\n",
    "        if n_users > 0:\n",
    "            extra_users = torch.rand(n_users, self.params.emb_size).to(device) \\\n",
    "                          if self.params.cuda \\\n",
    "                          else torch.rand(n_users, self.params.emb_size)\n",
    "\n",
    "            self.user_emb.weight = torch.nn.Parameter(torch.cat([self.user_emb.weight, extra_users], dim=0))\n",
    "            self.user_emb.num_embeddings = self.user_emb.weight.shape[0]   \n",
    "            \n",
    "        if n_questions > 0:\n",
    "            extra_questions = torch.rand(n_questions, self.params.emb_size).to(device) \\\n",
    "                              if self.params.cuda \\\n",
    "                              else torch.rand(n_questions, self.params.emb_size)\n",
    "            \n",
    "            self.question_emb.weight = torch.nn.Parameter(torch.cat([self.question_emb.weight, extra_questions], dim=0))\n",
    "            self.question_emb.num_embeddings = self.question_emb.weight.shape[0]\n",
    "    \n",
    "    \n",
    "    def forward(self, x_batch):\n",
    "        (b_user_task_ans_correct, b_user_item_correct_score, b_ans_correct_mean, b_ans_correct_count, b_prior_question_time_mean,\n",
    "        b_user_tag_correct_score, b_user_part_correct_score, b_prior_time, b_question_explained,\n",
    "        b_item_correct_mean) = x_batch\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "        input_sparse = torch.cat((b_user_task_ans_correct, b_user_item_correct_score, b_ans_correct_mean, b_ans_correct_count, b_prior_question_time_mean,\n",
    "                                  b_question_explained, b_prior_time, b_item_correct_mean), dim=1)\n",
    "        \n",
    "        # user\n",
    "        b_user_task_ans_correct = self.task_ans_correct_emb(b_user_task_ans_correct)\n",
    "        b_prior_question_time_mean = self.prior_time_mean(b_prior_question_time_mean)\n",
    "        b_ans_correct_mean = self.ans_mean(b_ans_correct_mean)\n",
    "        b_ans_correct_count = self.ans_count(b_ans_correct_count)\n",
    "        b_user_item_correct_score = self.user_question_correct_emb(b_user_item_correct_score)\n",
    "        b_user_tag_correct_score = self.user_tag_correct_emb(b_user_tag_correct_score)\n",
    "        b_user_part_correct_score = self.user_part_correct_emb(b_user_part_correct_score)\n",
    "        b_prior_time = self.prior_time(b_prior_time)\n",
    "        b_question_explained = self.prior_question_explained(b_question_explained)\n",
    "\n",
    "        # item\n",
    "#         b_item_id = self.question_emb(b_item_id).squeeze(1)\n",
    "#         b_item_part = self.part_emb(b_item_part)\n",
    "#         b_item_tags = self.tag_emb(b_item_tags)\n",
    "        b_item_correct_mean = self.question_correct_emb(b_item_correct_mean)\n",
    "        \n",
    "        input_emb = torch.cat((b_user_task_ans_correct, b_user_item_correct_score, b_ans_correct_mean, b_ans_correct_count, b_prior_question_time_mean,\n",
    "                               b_question_explained, b_prior_time, b_item_correct_mean), dim=-1)\n",
    "        \n",
    "        input_emb = input_emb.reshape(-1, self.params.n_features, self.params.emb_size)\n",
    "        \n",
    "        # FM-part\n",
    "        fm_out = self.fm_comp(input_emb, input_sparse)\n",
    "        \n",
    "        # Deep-part\n",
    "        input_emb = input_emb.reshape(-1, self.params.emb_size * self.params.n_features)\n",
    "        dnn_out = self.dnn_comp(input_emb)\n",
    "        \n",
    "        # Combine\n",
    "        out = torch.sigmoid(fm_out + dnn_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBMTrainer(object):\n",
    "    \n",
    "    def __init__(self, dataset, params):\n",
    "        \n",
    "        self.params = params\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.lgbm_params = {\n",
    "            'objective': 'binary',\n",
    "            'boosting' : 'gbdt',\n",
    "            'max_bin': 800,\n",
    "            'learning_rate': 0.0175,\n",
    "            'num_leaves': 80\n",
    "        }\n",
    "        self.model_lgbm = None\n",
    "        \n",
    "        self.selected_columns = ['answered_correctly', 'ans_correct_mean', 'ans_correct_count',\n",
    "                                 'prior_question_time_mean', 'task_ans_correct_mean',\n",
    "                                 'question_ans_correct_mean', 'lecture_question_correct_mean', \n",
    "                                 'user_question_part_scores_mean', 'user_question_tag_scores_mean',\n",
    "                                 'prior_question_had_explanation', 'prior_question_elapsed_time']\n",
    "    \n",
    "    def incre_update(self, data_batch, stat_batch, val_batch):\n",
    "        \n",
    "        # Stat-data\n",
    "        self.dataset.agg_newdata(stat_batch)\n",
    "#         pdb.set_trace()\n",
    "        # Traing-data\n",
    "        data_batch, n_newusers, n_newquestions, n_newlectures = self.dataset.set_batch(data_batch)\n",
    "     \n",
    "        self.params.update(**{\n",
    "            'num_users': self.dataset.n_users,\n",
    "            'num_questions': self.dataset.n_questions,\n",
    "            'num_lectures': self.dataset.n_lectures\n",
    "        })\n",
    "        \n",
    "        print(f'[Train] New cases: {n_newusers}, {n_newquestions}, {n_newlectures}')\n",
    "        print(f'[Train] All cases: {self.params.num_users}, {self.params.num_questions}, {self.params.num_lectures}')\n",
    "                \n",
    "        df_train = self.dataset.merge_df[self.selected_columns]\n",
    "        df_train_x = df_train.loc[:, df_train.columns != 'answered_correctly']\n",
    "        df_train_y = df_train['answered_correctly']\n",
    "        lgb_train = lgb.Dataset(df_train_x, df_train_y, \n",
    "                                categorical_feature = ['part', 'prior_question_had_explanation'])\n",
    "        \n",
    "        # Valid data\n",
    "        _, n_newusers, n_newquestions, n_newlectures = self.dataset.set_batch(val_batch)\n",
    "        print(f'------ [Valid] new-users: {n_newusers}')\n",
    "        df_val = self.dataset.merge_df[self.selected_columns]\n",
    "        df_val_x = df_val.loc[:, df_val.columns != 'answered_correctly']\n",
    "        df_val_y = df_val['answered_correctly']\n",
    "        lgb_val = lgb.Dataset(df_val_x, df_val_y, \n",
    "                              categorical_feature = ['part', 'prior_question_had_explanation'], \n",
    "                              reference=lgb_train)\n",
    "    \n",
    "        self.model_lgbm = lgb.train(self.lgbm_params, lgb_train,\n",
    "                                    valid_sets=[lgb_train, lgb_val],\n",
    "                                    verbose_eval=50,\n",
    "                                    num_boost_round=10000,\n",
    "                                    early_stopping_rounds=12,\n",
    "                                    init_model = self.model_lgbm if self.model_lgbm is not None else None)\n",
    "        \n",
    "        y_pred = self.model_lgbm.predict(df_val_x)\n",
    "        y_true = np.array(df_val_y)\n",
    "        auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "        acc = metrics.accuracy_score(y_true, (y_pred >= 0.5).astype(int))\n",
    "        \n",
    "        print(f'AUC: {auc} -- ACC: {acc}')\n",
    "        \n",
    "        self.dataset.agg_newdata(data_batch)\n",
    "        \n",
    "        lgb.plot_importance(self.model_lgbm)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4842f1e1-0d17-4ffa-ba35-79559ced3bfe",
    "_uuid": "29510dd4-5c35-4a00-8acd-ef1ad2ac0a68"
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \n",
    "    def __init__(self, dataset, params):\n",
    "        \n",
    "        self.params = params\n",
    "        self.dataset = dataset\n",
    "        self.model = DEEPFM(params)\n",
    "               \n",
    "        if params.cuda:\n",
    "            print('Moving model to gpus ...')\n",
    "            self.model.to(device)\n",
    "            \n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=params.learning_rate)\n",
    "        self.criteria = nn.BCELoss()\n",
    "                \n",
    "        \n",
    "    def get_dataloader(self, batch_size):\n",
    "        data_loader = DataLoader(self.dataset, \n",
    "                                 batch_size=batch_size, \n",
    "                                 drop_last=False,\n",
    "                                 num_workers=4,\n",
    "                                 shuffle=True)\n",
    "        return data_loader\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        # save model as .pt or .pth file\n",
    "        torch.save(self.model.state_dict(), save_path)\n",
    "            \n",
    "    def load_model(self, model_path):\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            checkpoint = torch.load(model_path)\n",
    "        else:\n",
    "            # this helps avoid errors when loading single-GPU-trained weights onto CPU-model\n",
    "            checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "            \n",
    "        self.model.load_state_dict(checkpoint)\n",
    "\n",
    "    def infer(self, databatch):\n",
    "        \n",
    "        # All test-cases\n",
    "        num_test = len(databatch.loc[databatch['content_type_id'] == 0])\n",
    "        if num_test == 0:\n",
    "            return []\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        n_users, n_questions, n_lectures, = self.dataset.test_batch(databatch)\n",
    "#         print(f'[Infer] New cases: {n_users}, {n_questions}, {n_lectures}')\n",
    "        \n",
    "        # add new entries to model\n",
    "#         self.model.update_size(n_users, n_questions, n_lectures)\n",
    "        \n",
    "        batch_size = min(num_test, self.params.batch_size)\n",
    "        test_loader = DataLoader(self.dataset, \n",
    "                                 batch_size=batch_size, \n",
    "                                 drop_last=False,\n",
    "                                 num_workers=4,\n",
    "                                 shuffle=False)\n",
    "        test_outputs = []\n",
    "        for i, test_batch in enumerate(test_loader):\n",
    "            input_batch = ()\n",
    "            for feature in test_batch[:-1]:\n",
    "                input_batch += (feature.to(device) if self.params.cuda else feature, )\n",
    "\n",
    "            output_batch = self.model(input_batch).detach()\n",
    "#             assert torch.isnan(output_batch).any() == False, 'NAN in prediction!'\n",
    "            test_outputs.append(output_batch.cpu().numpy() if self.params.cuda else output_batch.numpy())\n",
    "        \n",
    "        test_outputs = np.concatenate(test_outputs, axis=0).squeeze(1)\n",
    "#         assert num_test == len(test_outputs)\n",
    "        \n",
    "        return test_outputs\n",
    "    \n",
    "    def incre_update(self, data_batch, stat_batch, val_batch):\n",
    "        \n",
    "        self.dataset.agg_newdata(stat_batch)\n",
    "        \n",
    "        _, n_newusers, n_newquestions, n_newlectures = self.dataset.set_batch(data_batch)\n",
    "     \n",
    "        self.params.update(**{\n",
    "            'num_users': self.dataset.n_users,\n",
    "            'num_questions': self.dataset.n_questions,\n",
    "            'num_lectures': self.dataset.n_lectures\n",
    "        })\n",
    "        \n",
    "        print(f'[Train] New cases: {n_newusers}, {n_newquestions}, {n_newlectures}')\n",
    "        print(f'[Train] All cases: {self.params.num_users}, {self.params.num_questions}, {self.params.num_lectures}')\n",
    "\n",
    "#         self.model.update_size(n_newusers, n_newquestions, n_newlectures)\n",
    "        self.train()\n",
    "        \n",
    "        # VALID\n",
    "        self.val(val_batch)\n",
    "        \n",
    "        # Add the rest\n",
    "        self.dataset.agg_newdata(data_batch)\n",
    "        self.dataset.agg_newdata(val_batch)\n",
    "            \n",
    "    def finetune_batch(self):\n",
    "        # update batch-data for finetuning\n",
    "        is_finetune = self.dataset.finetune_batch()\n",
    "        if is_finetune:\n",
    "            batch_size = min(self.params.batch_size, len(self.dataset))\n",
    "            \n",
    "            # start finetune model\n",
    "            self.model.train()\n",
    "            train_loader = self.get_dataloader(batch_size)\n",
    "            self.train_step(train_loader, print_step=100, msg='Finetune')\n",
    "\n",
    "    def train_step(self, train_loader, print_step=200, msg='Train'):\n",
    "        self.model.train()\n",
    "        train_auc = AverageMeter()\n",
    "        for i, databatch in enumerate(train_loader):\n",
    "            \n",
    "            # Move to device\n",
    "            input_batch = ()\n",
    "            for feature in databatch[:-1]:\n",
    "                input_batch += (feature.to(device) if self.params.cuda else feature, )\n",
    "            b_target = databatch[-1].to(device) if self.params.cuda else databatch[-1]\n",
    "            \n",
    "            # FW model\n",
    "            output_batch = self.model(input_batch)     \n",
    "            loss = self.criteria(output_batch, b_target)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "                        \n",
    "            if not self.params.is_test:\n",
    "                if self.params.cuda:\n",
    "                    b_target = b_target.cpu().numpy()\n",
    "                    output_batch = output_batch.detach().cpu().numpy()\n",
    "                else:\n",
    "                    b_target = b_target.numpy()\n",
    "                    output_batch = output_batch.detach().numpy()\n",
    "                try:\n",
    "                    acc = metrics.accuracy_score(b_target, (output_batch >= 0.5).astype(int))\n",
    "                    auc = metrics.roc_auc_score(b_target, output_batch)\n",
    "                    train_auc.update(auc, b_target.shape[0])\n",
    "                except:\n",
    "                    auc, acc = None, None\n",
    "                    pass\n",
    "\n",
    "                if print_step > 0 and i % print_step == 0:\n",
    "                    print(f'+++ [{msg}] Loss: {loss.item()} AUC: {auc} ACC: {acc}')\n",
    "                    \n",
    "        if not self.params.is_test:\n",
    "            print(f'>>> [{msg}] TOTAL AUC: {train_auc.avg}')\n",
    "            \n",
    "    def val_step(self, val_loader, print_step=300, msg='Valid'):\n",
    "        self.model.eval()\n",
    "        val_auc = AverageMeter()\n",
    "        for i, databatch in enumerate(val_loader):\n",
    "            \n",
    "            # Move to device\n",
    "            input_batch = ()\n",
    "            for feature in databatch[:-1]:\n",
    "                input_batch += (feature.to(device) if self.params.cuda else feature, )\n",
    "            b_target = databatch[-1].to(device) if self.params.cuda else databatch[-1]\n",
    "            \n",
    "            # FW model\n",
    "            output_batch = self.model(input_batch)     \n",
    "                       \n",
    "            if self.params.cuda:\n",
    "                b_target = b_target.cpu().numpy()\n",
    "                output_batch = output_batch.detach().cpu().numpy()\n",
    "            else:\n",
    "                b_target = b_target.numpy()\n",
    "                output_batch = output_batch.detach().numpy()\n",
    "\n",
    "            try:\n",
    "                acc = metrics.accuracy_score(b_target, (output_batch >= 0.5).astype(int))\n",
    "                auc = metrics.roc_auc_score(b_target, output_batch)\n",
    "                val_auc.update(auc, b_target.shape[0])\n",
    "            except:\n",
    "                auc, acc = None, None\n",
    "                pass\n",
    "            \n",
    "            if print_step > 0 and i % print_step == 0:\n",
    "                print(f'- [{msg}] AUC: {auc} ACC: {acc}')\n",
    "        \n",
    "        print(f'>>> [{msg}] TOTAL AUC: {val_auc.avg}')\n",
    "    \n",
    "    def val(self, val_batch):\n",
    "        _, n_newusers, n_newquestions, n_newlectures = self.dataset.set_batch(val_batch)\n",
    "        print(f'------ [Valid] new-users: {n_newusers}')\n",
    "        val_loader = self.get_dataloader(self.params.batch_size)\n",
    "        self.model.update_size(n_newusers, n_newquestions, n_newlectures)\n",
    "        self.val_step(val_loader, print_step=400)\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        train_loader = self.get_dataloader(self.params.batch_size)\n",
    "        for epoch in range(self.params.n_epoch):\n",
    "            print(f'Epoch: {epoch}')\n",
    "            self.train_step(train_loader, print_step=200)    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09b9a9ab-fc3e-4754-b7a7-1306e7ad3681",
    "_uuid": "fecc0823-9724-4461-b981-b9f77072f0af"
   },
   "source": [
    "# Training all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_train_to_test(train_part, group=0):\n",
    "    train_part.loc[train_part['answered_correctly']==-1, 'answered_correctly'] = 0\n",
    "    train_part['answered_correctly'] = train_part['answered_correctly'].astype(str)\n",
    "    train_part = train_part.rename(columns={'answered_correctly': 'prior_group_answers_correct'})\n",
    "    train_part.iloc[0, 7] = '[' + ','.join(train_part['prior_group_answers_correct'].values) + ']'\n",
    "#     train_part.loc[:, 'content_type_id'] = [1 if np.random.rand() > 1./1e4 else 0 for _ in range(train_part.shape[0])] \n",
    "    train_part.loc[:, 'content_type_id'] = [1 if np.random.rand() > 0.5 else 0 for _ in range(train_part.shape[0])] \n",
    "#     train_part.loc[:, 'content_type_id'] = 1\n",
    "\n",
    "    train_part['group_num'] = [group]*train_part.shape[0]\n",
    "    train_part = train_part.set_index('group_num')\n",
    "    \n",
    "    return train_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mini_chunks(data_chunk, csize=int(1e5)):\n",
    "    data_chunk = data_chunk.sort_values(by ='timestamp')\n",
    "    for i in range(0, int(data_chunk.shape[0]), csize):\n",
    "        yield data_chunk.iloc[i:i+csize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_all(ml_trainer):\n",
    "    ml_trainer.dataset.reset_index()\n",
    "    ml_trainer.dataset.user_df.to_parquet('./save/user_df.gzip',compression='gzip')\n",
    "    ml_trainer.dataset.question_df.to_parquet('./save/question_df.gzip',compression='gzip')\n",
    "    ml_trainer.dataset.lecture_df.to_parquet('./save/lecture_df.gzip',compression='gzip')\n",
    "    ml_trainer.dataset.task_df.to_parquet('./save/task_df.gzip',compression='gzip')\n",
    "\n",
    "    ml_trainer.dataset.lecture_question_scores.to_parquet('./save/lecture_question_scores.gzip',compression='gzip')\n",
    "    ml_trainer.dataset.user_question_tag_scores.to_parquet('./save/user_question_tag_scores.gzip',compression='gzip')\n",
    "    ml_trainer.dataset.user_question_part_scores.to_parquet('./save/user_question_part_scores.gzip',compression='gzip')\n",
    "\n",
    "    f = h5py.File('./save/data2idx.h5', 'w')\n",
    "    f.create_dataset('user2idx', data=list(ml_trainer.dataset.user2idx.keys()))\n",
    "    f.create_dataset('question2idx', data=list(ml_trainer.dataset.question2idx.keys()))\n",
    "    f.create_dataset('lecture2idx', data=list(ml_trainer.dataset.lecture2idx.keys()))\n",
    "    f.close()\n",
    "\n",
    "    joblib.dump(ml_trainer.dataset.scaler_ans_correct_mean, './save/scaler_ans_correct_mean.save') \n",
    "    joblib.dump(ml_trainer.dataset.scaler_ans_correct_count, './save/scaler_ans_correct_count.save') \n",
    "    joblib.dump(ml_trainer.dataset.scaler_prior_question_elapsed_time, './save/scaler_prior_question_elapsed_time.save')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "params.load_state = False\n",
    "# save_part = None\n",
    "if params.load_state:\n",
    "    print(f'LOADING ALL DATASET ...')\n",
    "    mydata = LectureData(params) \n",
    "    trainer = Trainer(mydata, params)\n",
    "    \n",
    "    # filter data to speedup infer-time\n",
    "#     trainer.dataset.user_df = trainer.dataset.user_df.iloc[:1000]\n",
    "    trainer.dataset.lecture_question_scores = trainer.dataset.lecture_question_scores.iloc[-10000:]\n",
    "    trainer.dataset.user_question_tag_scores = trainer.dataset.user_question_tag_scores.iloc[-10000:]\n",
    "    trainer.dataset.user_question_part_scores = trainer.dataset.user_question_part_scores.iloc[-10000:]\n",
    "    \n",
    "    print('LOADING PRETRAINED MODEL ...')\n",
    "    trainer.load_model(os.path.join(params.extra_dir, 'model_latest.pth'))\n",
    "    \n",
    "else:\n",
    "    print(f'STARTING TRAINING FROM SCRATCH ...')\n",
    "    mydata = None\n",
    "    trainer = None\n",
    "    start = time.time()\n",
    "    for n, train_part in enumerate(chunks):\n",
    "        mini_chunks = gen_mini_chunks(train_part)\n",
    "        for train_part in mini_chunks:\n",
    "#             train_part = train_part.sample(frac=0.01)      \n",
    "            rest_part, valid_part = split_data(train_part, n_tail=6)\n",
    "            stat_part, train_part = split_data(rest_part, n_tail=18)\n",
    "        \n",
    "            print(f'Train: {train_part.shape} / Stats: {stat_part.shape} / Valid: {valid_part.shape}')\n",
    "            train_part = train_part.sort_values(by ='timestamp')\n",
    "\n",
    "            print(f'***Training chunk-{n}:')\n",
    "            if trainer is None:\n",
    "                mydata = LectureData(params, train_part, questions.copy(), lectures.copy())  \n",
    "                n_users, n_questions, n_lectures = mydata.n_users, mydata.n_questions, mydata.n_lectures\n",
    "                params.update(**{\n",
    "                    'num_users': n_users,\n",
    "                    'num_questions': n_questions,\n",
    "                    'num_lectures': n_lectures\n",
    "                })\n",
    "                print(f'[Train] All cases: {n_users}, {n_questions}, {n_lectures}')\n",
    "                trainer = Trainer(mydata, params)\n",
    "    #             trainer = GBMTrainer(mydata, params)\n",
    "\n",
    "            else:\n",
    "#                 train_part = convert_train_to_test(train_part, group=n)\n",
    "#                 s1 = time.time()\n",
    "#                 pred = trainer.infer(train_part)\n",
    "#                 trainer.finetune_batch()\n",
    "#                 print(f'Testing Time: {time.time() - s1}')\n",
    "#                 continue\n",
    "\n",
    "                trainer.incre_update(train_part, stat_part, valid_part)\n",
    "\n",
    "        if n >= params.n_chunks:\n",
    "            break\n",
    "                \n",
    "        print(f'Batch-Time elapsed: {time.time() - start}')\n",
    "\n",
    "    print(f'Training finished in {time.time() - start} seconds')\n",
    "    \n",
    "    #--------------\n",
    "    trainer.save_model('./save/model_latest.pth')\n",
    "    dump_all(trainer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2ce63614-a288-4be0-ae66-49df369340ca",
    "_uuid": "7bbfc78f-7707-4d61-9bf1-84dc7228a516"
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "# You can only call make_env() once, so don't lose it!\n",
    "env = riiideducation.make_env()\n",
    "\n",
    "# You can only iterate through a result from `env.iter_test()` once\n",
    "# so be careful not to lose it once you start iterating.\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Submission\n",
    "################################\n",
    "\n",
    "print(f'Start testing ....')\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    # do prediction\n",
    "    pred = trainer.infer(test_df)\n",
    "\n",
    "    # fill all value first\n",
    "    test_df['answered_correctly'] = 0.5\n",
    "    \n",
    "    # Only fill question-type\n",
    "    test_df.loc[test_df['content_type_id'] == 0, 'answered_correctly'] = pred\n",
    "\n",
    "    # submit prediction    \n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n",
    "    \n",
    "    trainer.finetune_batch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
