{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "fd8ff387-9c14-47ff-955d-d0bd1fd9b10d",
    "_uuid": "8554fa27-784e-4f25-b627-fdaf4f3dd959"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pdb\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datatable as dt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle\n",
    "import h5py\n",
    "import joblib\n",
    "\n",
    "# import seaborn as sns\n",
    "# import lightgbm as lgb\n",
    "# from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install latest_bert/dist/bert_src-1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latest_bert.src.bert_src.modeling_bert import RiidModel\n",
    "from latest_bert.src.bert_src.configuration_bert import BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "fbf87edc-04b9-435e-80f1-d6554c756d73",
    "_uuid": "53e8bc27-466e-47ab-9591-c8ffcd0d871c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:7\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda:7\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "c8848800-3d8b-4aa7-b0c5-e807ee7efd20",
    "_uuid": "cd990caf-b201-4f01-b7d5-77abb022832e"
   },
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        \n",
    "    def update(self, **kargs):\n",
    "        self.__dict__.update(kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "29a04d21-8112-44d0-827d-989ea07596ad",
    "_uuid": "45665757-b2d9-483e-8c2a-9dffbc5c54e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question shapes: (13523, 5)\n",
      "Lecture shapes: (418, 4)\n"
     ]
    }
   ],
   "source": [
    "path = './kaggle/input/riiid-test-answer-prediction'\n",
    "train_file = f'{path}/train.csv'\n",
    "train_dtypes = {'row_id': 'int64',\n",
    "              'timestamp': 'int64',\n",
    "              'user_id': 'int32',\n",
    "              'content_id': 'int16',\n",
    "              'content_type_id': 'int8',\n",
    "              'task_container_id': 'int16',\n",
    "              'user_answer': 'int8',\n",
    "              'answered_correctly': 'int8',\n",
    "              'prior_question_elapsed_time': 'float32', \n",
    "              'prior_question_had_explanation': 'boolean',\n",
    "             }\n",
    "test_file = f'{path}/example_test.csv'\n",
    "test_sample = pd.read_csv(test_file)\n",
    "questions = pd.read_csv(f'{path}/questions.csv')\n",
    "lectures = pd.read_csv(f'{path}/lectures.csv')\n",
    "print('Question shapes:', questions.shape)\n",
    "print('Lecture shapes:', lectures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id', 'task_container_id', 'user_answer', 'answered_correctly', 'prior_question_elapsed_time', 'prior_question_had_explanation']\n",
    "# chunks = pd.read_csv(train_file, chunksize=1e3, dtype=train_dtypes, header=None, names=colnames, index_col=False)\n",
    "chunks = pd.read_csv(train_file, chunksize=1e5, dtype=train_dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3bbb0f25-3253-480b-a4e3-8ab9adf15b7b",
    "_uuid": "fd79f190-cdc1-4284-b283-36814a278f03"
   },
   "outputs": [],
   "source": [
    "question_tags = list(map(lambda x: map(lambda v: int(v) + 1, str(x).split()) if str(x).strip() != 'nan' else [0], questions.tags.values))\n",
    "question_tags = list(set(itertools.chain(*question_tags)))\n",
    "\n",
    "n_tags = len(question_tags)\n",
    "n_parts = len(set(questions.part.unique())) + 1\n",
    "\n",
    "print(f'n_tags {n_tags}, n_parts {n_parts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2408117-b91d-4c63-aa61-687b7228e13a",
    "_uuid": "e4c605ce-e959-4234-9b30-9f5f6d95fa5f"
   },
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    'is_update_train': True,\n",
    "    'is_update_valid': False,\n",
    "    'load_state': True,\n",
    "    'use_buffer': False,\n",
    "    'is_offline': False,\n",
    "    'batch_norm': False,\n",
    "    'is_test': False,\n",
    "    'n_chunks': 200,\n",
    "    'n_epoch': 10,\n",
    "    'learning_rate': 5e-5,\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 4,\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'num_questions': questions.question_id.nunique(),\n",
    "    'num_lectures': lectures.lecture_id.nunique(),\n",
    "    'num_total_q_tags': n_tags,\n",
    "    'max_len_tags': 6,\n",
    "    'num_total_q_part': n_parts,\n",
    "    'n_layers': 2,\n",
    "    'dropout': 0.1,\n",
    "    'hidden_size': 256,\n",
    "    'max_position_embeddings': 256,\n",
    "    'num_hidden_layers': 4,\n",
    "    'num_attention_heads': 8,\n",
    "    'intermediate_size': 1024,\n",
    "    'max_task_size': 10002,\n",
    "    'lag_size': 720,\n",
    "    'ans_size': 3,\n",
    "    'buffer_size_limit': 1e4,\n",
    "    'max_seq_length': 100,\n",
    "    'extra_dir':'./save/bert_save',\n",
    "    'save_dir': './save/bert_save'\n",
    "}\n",
    "params = Params(**params_dict)\n",
    "print(params.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_part, n_tail=10):\n",
    "    valid = train_part.groupby('user_id').tail(n_tail)\n",
    "    train = train_part[~train_part.index.isin(valid.index)]\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['time_shift'] = test_sample['timestamp'].copy()\n",
    "test_sample['time_shift'] = test_sample.groupby('user_id')['time_shift'].shift()\n",
    "test_sample['lag_time'] = (test_sample['timestamp'] - test_sample['time_shift'] - test_sample['prior_question_elapsed_time']) // 100\n",
    "test_sample['lag_time'] = test_sample['lag_time'].map(lambda x: x if (x != np.nan and x > 0) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LectureData(Dataset):\n",
    "    \n",
    "    def __init__(self, params, question_df=None, lecture_df=None, is_train=True):\n",
    "        # read init-data\n",
    "        self.params = params\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        self.features = ['combined_id', 'content_type_id', 'task_container_id', \n",
    "                         'answered_correctly','prior_question_elapsed_time', 'part', 'tags', 'prior_question_elapsed_time']\n",
    "        \n",
    "        self.train_columns = ['user_id', 'content_id', 'content_type_id', 'task_container_id', 'timestamp',\n",
    "                              'answered_correctly', 'prior_question_elapsed_time', 'row_id']\n",
    "        \n",
    "        self.prior_batch, self.current_batch, self.buffer_df, self.batch_user, self.question_df = None, None, None, None, None\n",
    "        self.user_dict, self.question2idx, self.lecture2idx = None, None, None\n",
    "        \n",
    "        # Restore all data\n",
    "        if params.load_state:\n",
    "            self.load_state()\n",
    "        else:\n",
    "            self.init_info(question_df, lecture_df)\n",
    "\n",
    "    def init_info(self, question_df, lecture_df):\n",
    "        \n",
    "        self.question_df = self.proc_questiondata(question_df)\n",
    "        \n",
    "        self.question_list = list(question_df['question_id'].unique())\n",
    "        self.lecture_list = list(lecture_df['lecture_id'].unique())\n",
    "\n",
    "        self.n_questions = len(self.question_list)\n",
    "        self.n_lectures = len(self.lecture_list)\n",
    "        \n",
    "        self.question2idx = dict(zip(self.question_list, range(1, self.n_questions + 1))) # 0 for padding\n",
    "        self.lecture2idx = dict(zip(self.lecture_list, range(self.n_questions + 1, self.n_questions + 1 + self.n_lectures)))\n",
    "        \n",
    "    def load_state(self):  \n",
    "        \n",
    "        print('Loading data state ...')\n",
    "        f = h5py.File(os.path.join(self.params.extra_dir, 'data2idx.h5'), 'r')\n",
    "        \n",
    "        self.question2idx = f['question2idx'][:]\n",
    "        self.n_questions = len(self.question2idx)\n",
    "        self.question2idx = dict(zip(self.question2idx, range(1, self.n_questions + 1)))\n",
    "        \n",
    "        self.lecture2idx = f['lecture2idx'][:]\n",
    "        self.n_lectures = len(self.lecture2idx)\n",
    "        self.lecture2idx = dict(zip(self.lecture2idx, range(self.n_questions + 1, self.n_questions + 1 + self.n_lectures)))\n",
    "        f.close()\n",
    "        \n",
    "        with open(os.path.join(self.params.extra_dir, 'user_dict.pickle'), 'rb') as handle:\n",
    "            self.user_dict = pickle.load(handle)\n",
    "\n",
    "\n",
    "    def proc_traindata(self, train_df):\n",
    "        \n",
    "        train_df['prior_question_elapsed_time'].fillna(0, inplace=True)\n",
    "        \n",
    "#         train_df['prior_question_had_explanation'].fillna(False, inplace=True)\n",
    "#         train_df['prior_question_had_explanation'] = train_df['prior_question_had_explanation'].astype(int)        \n",
    "#         train_df['prior_question_elapsed_time'] = train_df['prior_question_elapsed_time'].map(lambda x: np.log(x + 1.))\n",
    "\n",
    "        train_df['combined_id'] = train_df.apply(lambda x: self.question2idx[x['content_id']], axis=1) \n",
    "#                                                  if x['content_type_id']==0 \n",
    "#                                                  else self.lecture2idx[x['content_id']], axis=1)\n",
    "#         train_df['task_container_id'].fillna(-1, inplace=True)\n",
    "        train_df['task_container_id'] = train_df['task_container_id'].map(lambda x: x + 1)\n",
    "#         pdb.set_trace()\n",
    "        train_df['time_shift'] = train_df['timestamp'].copy()\n",
    "        train_df['time_shift'] = train_df.groupby('user_id')['time_shift'].shift()\n",
    "        train_df['lag_time'] = (train_df['timestamp'] - train_df['time_shift'] - train_df['prior_question_elapsed_time']) // 500\n",
    "        train_df['lag_time'] = train_df['lag_time'].map(lambda x: x if (x != np.nan and x > 0 and x < self.params.lag_size) else 0).astype(int)\n",
    "\n",
    "        train_df[\"prior_question_elapsed_time\"] = train_df[\"prior_question_elapsed_time\"] // 1000\n",
    "\n",
    "        return train_df\n",
    "        \n",
    "    def proc_questiondata(self, question_df):\n",
    "        \n",
    "        def _convert_vector(q_ids):\n",
    "            blank_vector = np.zeros(self.params.num_total_q_tags).astype(int)\n",
    "            blank_vector[q_ids] = 1\n",
    "            return blank_vector\n",
    "        \n",
    "        question_df.tags.fillna('-1', inplace=True)\n",
    "        question_df['tags'] = question_df['tags'].map(lambda x: list(map(lambda s: int(s) + 1, str(x).split())))\n",
    "        question_df['tags'] = question_df['tags'].map(_convert_vector)\n",
    "#         question_df['part'] = question_df['part'].map(lambda x: x - 1)\n",
    "        \n",
    "        return question_df\n",
    "            \n",
    "    def test_batch(self, batch_df):\n",
    "        \n",
    "        self.is_train = False\n",
    "        \n",
    "        # fetch prior labels\n",
    "        gt_prior_batch = eval(batch_df.iloc[0][\"prior_group_answers_correct\"])\n",
    "        \n",
    "        # HERE stop updating first for 1st submission\n",
    "        if self.current_batch is not None and len(gt_prior_batch) > 0:\n",
    "            # save prior-batch with labels\n",
    "            self.prior_batch = self.current_batch\n",
    "            \n",
    "            # Assign label to prev-batch\n",
    "            self.prior_batch['answered_correctly'] = gt_prior_batch\n",
    "            self.prior_batch = self.prior_batch[self.train_columns]\n",
    "            \n",
    "            # add to buffer-df\n",
    "            if self.params.use_buffer:\n",
    "                self.buffer_df = pd.concat([self.buffer_df, self.prior_batch], axis=0, ignore_index=True)\n",
    "             \n",
    "        else:\n",
    "            self.prior_batch = batch_df\n",
    "        \n",
    "        self.current_batch = batch_df\n",
    "        # create dummy labels \"2\", later will be replaced\n",
    "        self.current_batch['answered_correctly'] = 2\n",
    "        \n",
    "        test_user_dict = self.proc_batch(self.current_batch)\n",
    "        test_user_dict = self.update_newdata(test_user_dict) # append user history\n",
    "        \n",
    "        self.batch_user = list(test_user_dict.items())\n",
    "        \n",
    "        return len(self.batch_user)        \n",
    "            \n",
    "    def finetune_batch(self, is_finetune=False):\n",
    "        \n",
    "        self.is_train = True\n",
    "        \n",
    "        if self.buffer_df is not None and len(self.buffer_df) > params.buffer_size_limit:\n",
    "\n",
    "            print('--> Dataset activated finetune buffer')\n",
    "            buff_user_dict = self.proc_batch(self.buffer_df)\n",
    "            \n",
    "            # update user_dict later on\n",
    "            buff_update = self.update_newdata(buff_user_dict)\n",
    "            self.user_dict.update(buff_update)\n",
    "            \n",
    "            if is_finetune:\n",
    "                # create data for continue training\n",
    "                self.batch_user = list(buff_update.items())\n",
    "            \n",
    "            self.buffer_df = None\n",
    "            \n",
    "            # check user_dict size\n",
    "            cur_size_in_gb = sys.getsizeof(self.user_dict) // (1024**3)\n",
    "            if cur_size_in_gb > 12:\n",
    "                print('--> Random removing user-entries')\n",
    "                for i in range(int(len(self.user_dict) * 0.01)):\n",
    "                    self.user_dict.pop(random.choice(self.user_dict.keys()))\n",
    "                   \n",
    "            return is_finetune\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def proc_batch(self, batch_df):\n",
    "        \n",
    "#         batch_df = batch_df.sort_values(by ='timestamp')\n",
    "        batch_df = batch_df[batch_df.content_type_id==0]\n",
    "        batch_df = self.proc_traindata(batch_df)\n",
    "        \n",
    "        batch_df = batch_df.merge(self.question_df, left_on='content_id', right_on='question_id', how='left')\n",
    "        \n",
    "#         batch_df['prev_answered_correctly'] = batch_df['answered_correctly'].shift().fillna(2)\n",
    "\n",
    "        if not self.is_train:\n",
    "            batch_df['position'] = range(batch_df.shape[0])\n",
    "            user_group = batch_df.groupby('user_id').agg({\n",
    "                'combined_id': list,\n",
    "                'content_type_id': list,\n",
    "                'task_container_id': list,\n",
    "                'answered_correctly': list,\n",
    "                'prior_question_elapsed_time': list,\n",
    "                'position': list, # only for testing,\n",
    "                'tags': list,\n",
    "                'part': list,\n",
    "                'lag_time': list,\n",
    "                'row_id': 'count'\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            user_group = batch_df.groupby('user_id').agg({\n",
    "                'combined_id': list,\n",
    "                'content_type_id': list,\n",
    "                'task_container_id': list,\n",
    "                'answered_correctly': list,\n",
    "                'prior_question_elapsed_time': list,\n",
    "                'tags': list,\n",
    "                'part': list,\n",
    "                'lag_time': list,\n",
    "                'row_id': 'count'\n",
    "            })\n",
    "            \n",
    "#             print(f\"---> Stats: avg_entries_in_batch {user_group['prior_question_elapsed_time'].mean()}\")\n",
    "#             user_group.drop(['prior_question_elapsed_time'], axis=1, inplace=True)\n",
    "            \n",
    "        batch_user_dict = user_group.to_dict('index')\n",
    "        return batch_user_dict\n",
    "    \n",
    "    def set_batch(self, train_df):\n",
    "        \n",
    "        self.is_train = True\n",
    "        \n",
    "        train_user_dict = self.proc_batch(train_df)\n",
    "        \n",
    "        self.batch_user = list(train_user_dict.items())\n",
    "        \n",
    "        return len(self.batch_user), train_user_dict\n",
    "    \n",
    "    def val_batch(self, valid_df):\n",
    "        \n",
    "        self.is_train = False\n",
    "        \n",
    "        valid_user_dict = self.proc_batch(valid_df)\n",
    "        \n",
    "        valid_user_dict = self.update_newdata(valid_user_dict)\n",
    "        self.user_dict.update(valid_user_dict)\n",
    "        \n",
    "        self.batch_user = list(valid_user_dict.items())\n",
    "                \n",
    "        return len(self.batch_user)\n",
    "    \n",
    "    def late_update(self, data_dict):\n",
    "        \n",
    "        data_update = self.update_newdata(data_dict)\n",
    "        self.user_dict.update(data_update)\n",
    "    \n",
    "    def dummy_entry(self, user_id):\n",
    "        entry = {k:[] for k in self.features}\n",
    "        return entry\n",
    "    \n",
    "    def merge_train_valid(self, train_dict, valid_dict):\n",
    "        \n",
    "        merge_dict = dict()\n",
    "        for uid, udata in valid_dict.items():\n",
    "            if uid in train_dict:\n",
    "                merge_dict[uid] = [train_dict[uid], udata]\n",
    "            else:\n",
    "                merge_dict[uid] = [self.dummy_entry(uid), udata]\n",
    "        \n",
    "        return list(merge_dict.items())\n",
    "    \n",
    "    def _agg_dict(self, org_dict, new_dict):\n",
    "\n",
    "        for k in self.features:\n",
    "            new_value = (org_dict[k].copy() + new_dict[k])[-self.params.max_seq_length:]\n",
    "            new_dict[k] = new_value\n",
    "            \n",
    "        return new_dict\n",
    "        \n",
    "    def update_newdata(self, new_user_dict):\n",
    "        \n",
    "        if self.user_dict is None:\n",
    "            print('First init user_dict')\n",
    "            self.user_dict = new_user_dict\n",
    "            return new_user_dict\n",
    "        \n",
    "        common_users = list(set(new_user_dict.keys()) & set(self.user_dict.keys()))        \n",
    "        for uid in common_users:\n",
    "            new_user_dict[uid] = self._agg_dict(self.user_dict[uid], new_user_dict[uid])\n",
    "        \n",
    "        return new_user_dict\n",
    "\n",
    "    def padding(self, feature, padding_value=0, skip_first=False, first_value=0, max_len=64):\n",
    "        \n",
    "        if not skip_first:\n",
    "            feature = feature[-(max_len-1):]\n",
    "            return [first_value] + feature + [padding_value] * (max_len - 1 - len(feature)) \n",
    "        else:\n",
    "            feature = feature[-max_len:]\n",
    "            return feature + [padding_value] * (max_len - len(feature)) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.batch_user) if self.batch_user is not None else 0\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        ins = self.batch_user[index][1]        \n",
    "        target = np.array(self.padding(ins['answered_correctly'], max_len=self.params.max_seq_length)).astype(int)\n",
    "\n",
    "#         curr_ans = np.array([self.padding(ins[0]['answered_correctly'], first_value=2, max_len=self.params.max_seq_length), \n",
    "#                              np.insert(target[:-1], 0, 2)]).astype(int)\n",
    "        \n",
    "        curr_ans = np.array([2] * self.params.max_seq_length).astype(int)\n",
    "        \n",
    "        enc_att_len = len(ins['answered_correctly'][-(self.params.max_seq_length-1):])\n",
    "        enc_attention_mask = [0] + [1] * enc_att_len + [0] * (self.params.max_seq_length - enc_att_len - 1)\n",
    "                \n",
    "        attention_mask = np.array(enc_attention_mask).astype(int)\n",
    "                \n",
    "        content_type_id = np.array(self.padding(ins['content_type_id'], max_len=self.params.max_seq_length)).astype(int)\n",
    "        \n",
    "        combined_id = np.array(self.padding(ins['combined_id'], max_len=self.params.max_seq_length)).astype(int)\n",
    "        \n",
    "        task_container_id = np.array(self.padding(ins['task_container_id'], first_value=10001, max_len=self.params.max_seq_length)).astype(int)\n",
    "        \n",
    "        prior_time_id = np.array(self.padding(ins['prior_question_elapsed_time'], first_value=0, max_len=self.params.max_seq_length)).astype(int)\n",
    "        lag_time_id = np.array(self.padding(ins['lag_time'], first_value=0, max_len=self.params.max_seq_length)).astype(int)\n",
    "        \n",
    "        question_part_id = np.array(self.padding(ins['part'], first_value=0, max_len=self.params.max_seq_length)).astype(int)\n",
    "        tag_pad = [0]*self.params.num_total_q_tags\n",
    "        question_tag_id = np.array(self.padding(ins['tags'], padding_value=tag_pad, first_value=tag_pad, max_len=self.params.max_seq_length)).astype(int)\n",
    "        \n",
    "        if self.is_train:\n",
    "            return (torch.LongTensor(combined_id),\n",
    "                    torch.LongTensor(attention_mask),\n",
    "                    torch.LongTensor(content_type_id), \n",
    "                    torch.LongTensor(task_container_id),\n",
    "                    torch.LongTensor(curr_ans),\n",
    "                    torch.LongTensor(question_part_id),\n",
    "                    torch.FloatTensor(question_tag_id),\n",
    "                    torch.LongTensor(prior_time_id),\n",
    "                    torch.LongTensor(lag_time_id),\n",
    "                    torch.LongTensor(target)) \n",
    "        else:\n",
    "            history_mask = [0] * (enc_att_len - ins['row_id']) + [1] * ins['row_id']\n",
    "            history_mask = [0] + history_mask + [0] * (self.params.max_seq_length - len(history_mask) - 1)\n",
    "\n",
    "            position = np.array(self.padding(ins['position'], skip_first=True, max_len=self.params.max_seq_length, padding_value=-1)).astype(int)\n",
    "            \n",
    "            return (torch.LongTensor(combined_id),\n",
    "                    torch.LongTensor(attention_mask),\n",
    "                    torch.LongTensor(content_type_id), \n",
    "                    torch.LongTensor(task_container_id),\n",
    "                    torch.LongTensor(curr_ans),\n",
    "                    torch.LongTensor(question_part_id),\n",
    "                    torch.FloatTensor(question_tag_id),\n",
    "                    torch.LongTensor(prior_time_id),\n",
    "                    torch.LongTensor(history_mask),\n",
    "                    torch.LongTensor(position),\n",
    "                    torch.LongTensor(target)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_linear_layer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 output_size,\n",
    "                 activation=None):\n",
    "        super(Multi_linear_layer, self).__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        self.linears.append(nn.Linear(input_size, hidden_size))\n",
    "        for _ in range(1, n_layers - 1):\n",
    "            self.linears.append(nn.Linear(hidden_size, hidden_size))\n",
    "        self.linears.append(nn.Linear(hidden_size, output_size))\n",
    "        self.activation = getattr(F, activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for linear in self.linears[:-1]:\n",
    "            x = self.activation(linear(x))\n",
    "        linear = self.linears[-1]\n",
    "        x = linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiidClassifier(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(RiidClassifier, self).__init__()\n",
    "        \n",
    "        n_layers = params.n_layers\n",
    "        hidden_size = params.hidden_size\n",
    "        \n",
    "        self.logits = nn.Linear(hidden_size, 2)\n",
    "        \n",
    "        enc_bert_config = BertConfig(num_hidden_layers=params.num_hidden_layers,\n",
    "                                      max_position_embeddings=params.max_position_embeddings,\n",
    "                                      num_attention_heads=params.num_attention_heads,\n",
    "                                      intermediate_size=params.intermediate_size,\n",
    "                                      question_size=params.num_questions,\n",
    "                                      lecture_size=params.num_lectures,\n",
    "                                      task_size=params.max_task_size,\n",
    "                                      ans_size=params.ans_size,\n",
    "                                      part_size=params.num_total_q_part,\n",
    "                                      tag_size=params.num_total_q_tags,\n",
    "                                      lag_size=params.lag_size,\n",
    "                                      hidden_size=params.hidden_size,\n",
    "                                      hidden_dropout_prob=params.dropout,\n",
    "                                      output_attentions=False,\n",
    "                                      gradient_checkpointing=False)\n",
    "        \n",
    "#         dec_bert_config = BertConfig(num_hidden_layers=params.num_hidden_layers,\n",
    "#                                       max_position_embeddings=params.max_position_embeddings,\n",
    "#                                       num_attention_heads=params.num_attention_heads,\n",
    "#                                       intermediate_size=params.intermediate_size,\n",
    "#                                       question_size=params.num_questions,\n",
    "#                                       lecture_size=params.num_lectures,\n",
    "#                                       task_size=params.max_task_size,\n",
    "#                                       ans_size=params.ans_size,\n",
    "#                                       part_size=params.num_total_q_part,\n",
    "#                                       tag_size=params.num_total_q_tags,\n",
    "#                                       hidden_size=params.hidden_size,\n",
    "#                                       output_attentions=False,\n",
    "#                                       is_decoder=True,\n",
    "#                                       add_cross_attention=True)\n",
    "        \n",
    "        self.enc_model = RiidModel(enc_bert_config)\n",
    "#         self.dec_model = RiidModel(dec_bert_config)\n",
    "        \n",
    "    def forward(self, x_enc):\n",
    "        \n",
    "        enc_hidden, pooled_output = self.enc_model(**x_enc, return_dict=False) # [b, len, hsize], [b, hsize]\n",
    "#         pdb.set_trace()\n",
    "#         x_dec.update({'encoder_hidden_states': enc_hidden,\n",
    "#                       'encoder_attention_mask': x_enc['attention_mask']\n",
    "#         })\n",
    "#         dec_hidden, _ = self.dec_model(**x_dec, return_dict=False)\n",
    "        \n",
    "        cls_logits = self.logits(enc_hidden)\n",
    "        cls_outputs = nn.Softmax(dim=-1)(cls_logits)\n",
    "        \n",
    "        return cls_outputs # [b, len, 2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RiidClassifier(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4842f1e1-0d17-4ffa-ba35-79559ced3bfe",
    "_uuid": "29510dd4-5c35-4a00-8acd-ef1ad2ac0a68"
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \n",
    "    def __init__(self, dataset, params):\n",
    "        \n",
    "        self.params = params\n",
    "        self.dataset = dataset\n",
    "        self.model = RiidClassifier(params)\n",
    "        \n",
    "        if params.cuda:\n",
    "            print('Moving model to gpus ...')\n",
    "            self.model.to(device)\n",
    "            \n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=params.learning_rate)\n",
    "        self.criteria = nn.CrossEntropyLoss(reduction='none').to(device)\n",
    "                \n",
    "    def get_dict(self, batch_data, is_train=True):\n",
    "        \n",
    "        field_names = ['input_ids', 'attention_mask', 'token_type_ids', \n",
    "                       'task_ids', 'curr_ans', 'part_ids', 'tag_ids', \n",
    "                       'prior_time_ids', 'lag_time_ids']\n",
    "        enc_data = {}\n",
    "        for i, n in enumerate(field_names):\n",
    "            enc_entry = batch_data[i]\n",
    "            enc_data.update({n: enc_entry})\n",
    "#             dec_data.update({n: dec_entry.squeeze(1)})\n",
    "            \n",
    "        if is_train:\n",
    "            placeholder = batch_data[-1]\n",
    "            return enc_data, placeholder\n",
    "        \n",
    "        else:\n",
    "            history_mask = batch_data[-3]\n",
    "            placeholder = batch_data[-2]\n",
    "            return enc_data, placeholder, history_mask\n",
    "        \n",
    "        \n",
    "    def get_dataloader(self, batch_size, shuffle=True):\n",
    "        \n",
    "        data_loader = DataLoader(self.dataset, \n",
    "                                 batch_size=batch_size, \n",
    "                                 drop_last=False,\n",
    "                                 num_workers=4,\n",
    "                                 shuffle=shuffle)\n",
    "        return data_loader\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        # save model as .pt or .pth file\n",
    "        torch.save(self.model.state_dict(), f'{save_path}/model_latest.pth')\n",
    "        print('Finished saving model!')\n",
    "        \n",
    "    def save_data(self, save_path):\n",
    "        \n",
    "        f = h5py.File(f'{save_path}/data2idx.h5', 'w')\n",
    "        f.create_dataset('question2idx', data=list(self.dataset.question2idx.keys()))\n",
    "        f.create_dataset('lecture2idx', data=list(self.dataset.lecture2idx.keys()))\n",
    "        f.close()\n",
    "        \n",
    "        with open(f'{save_path}/user_dict.pickle', 'wb') as handle:\n",
    "            pickle.dump(self.dataset.user_dict, handle, protocol=3)\n",
    "            \n",
    "        print('Finished saving data!')\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            checkpoint = torch.load(model_path, map_location='cuda:0')\n",
    "        else:\n",
    "            # this helps avoid errors when loading single-GPU-trained weights onto CPU-model\n",
    "            checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "            \n",
    "        self.model.load_state_dict(checkpoint)\n",
    "        \n",
    "    def infer(self, databatch, is_valid=False):\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        # All test-cases\n",
    "        num_test = len(databatch[databatch['content_type_id'] == 0])\n",
    "        if num_test == 0:\n",
    "            return []\n",
    "        if not is_valid:\n",
    "            test_size = self.dataset.test_batch(databatch)\n",
    "        else:\n",
    "            test_size = self.dataset.val_batch(databatch)\n",
    "#         print(f'[Infer] New cases: {test_size}')\n",
    "        \n",
    "        batch_size = min(test_size, self.params.batch_size)\n",
    "        test_loader = DataLoader(self.dataset, \n",
    "                                 batch_size=batch_size, \n",
    "                                 drop_last=False,\n",
    "                                 num_workers=4,\n",
    "                                 shuffle=False)\n",
    "#         test_outputs = []\n",
    "        all_outputs = np.ones(num_test) * -1.\n",
    "        for i, test_batch in enumerate(test_loader):\n",
    "            input_batch = ()\n",
    "            for feature in test_batch:\n",
    "                input_batch += (feature.to(device) if self.params.cuda else feature, )\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "            enc_batch, position_batch, history_mask = self.get_dict(input_batch, is_train=False)\n",
    "\n",
    "            output_batch = self.model(enc_batch)[:,:,1].detach().cpu().numpy().reshape(-1, 1)\n",
    "            position_batch = position_batch.cpu().numpy().reshape(-1, 1)\n",
    "            history_mask = history_mask.cpu().numpy().reshape(-1, 1)\n",
    "            \n",
    "            output_batch = output_batch[history_mask==1]\n",
    "            position_batch = position_batch[position_batch!=-1]\n",
    "#             pdb.set_trace()\n",
    "            assert len(output_batch) == len(position_batch)\n",
    "            \n",
    "            all_outputs[position_batch] = output_batch\n",
    "            \n",
    "#             tmp = sorted(zip(output_batch, position_batch), key = lambda t: t[1])\n",
    "#             sorted_output = list(zip(*tmp))[0]\n",
    "#             test_outputs.append(sorted_output)\n",
    "        \n",
    "#         test_outputs = np.concatenate(test_outputs, axis=0)\n",
    "#         assert num_test == len(test_outputs), f'{num_test} # {len(test_outputs)}'\n",
    "        assert np.sum((all_outputs==-1).astype(int)) == 0\n",
    "        \n",
    "        return all_outputs\n",
    "    \n",
    "    def incre_update(self, stat_batch, train_batch, val_batch):\n",
    "        \n",
    "        self.train(train_batch)\n",
    "        \n",
    "        val_outputs = self.infer(val_batch, is_valid=True)\n",
    "        val_target = val_batch[val_batch.content_type_id==0]['answered_correctly'].values\n",
    "        \n",
    "        assert len(val_outputs) == len(val_target)\n",
    "        \n",
    "        auc = metrics.roc_auc_score(val_target, val_outputs)\n",
    "        print(f'>>> [VALID] AUC: {auc}')\n",
    "#         self.val(val_batch)\n",
    "                    \n",
    "    def finetune_batch(self):\n",
    "        # update batch-data for finetuning\n",
    "        is_finetune = self.dataset.finetune_batch(is_finetune=True)\n",
    "        if is_finetune:\n",
    "            batch_size = min(self.params.batch_size, len(self.dataset))\n",
    "            \n",
    "            # start finetune model\n",
    "            self.model.train()\n",
    "            train_loader = self.get_dataloader(batch_size)\n",
    "            self.train_step(train_loader, print_step=100, msg='Finetune')\n",
    "\n",
    "    def train_step(self, train_loader, print_step=200, msg='Train'):\n",
    "        \n",
    "        self.model.train()\n",
    "        train_auc = AverageMeter()\n",
    "        for i, databatch in enumerate(train_loader):\n",
    "            \n",
    "            # Move to device\n",
    "            input_batch = ()\n",
    "            for feature in databatch:\n",
    "                input_batch += (feature.to(device) if self.params.cuda else feature, )\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "            # Convert to dict-type\n",
    "            enc_batch, b_target = self.get_dict(input_batch)\n",
    "            \n",
    "            # FW model\n",
    "            output_batch = self.model(enc_batch)    \n",
    "            \n",
    "            with torch.no_grad():\n",
    "#                 pdb.set_trace()\n",
    "                attention_mask = enc_batch['attention_mask']\n",
    "\n",
    "#             assert output_batch.shape == b_target.shape\n",
    "            \n",
    "            loss = torch.sum(self.criteria(output_batch.reshape(-1, 2), b_target.reshape(-1)) * attention_mask.reshape(-1)) / torch.sum(attention_mask)\n",
    "#             pdb.set_trace()\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "                        \n",
    "            if not self.params.is_test:\n",
    "                if self.params.cuda:\n",
    "                    b_target = b_target.cpu().numpy()\n",
    "                    output_batch = output_batch.detach().cpu().numpy()\n",
    "                else:\n",
    "                    b_target = b_target.numpy()\n",
    "                    output_batch = output_batch.detach().numpy()\n",
    "                    \n",
    "                output_batch, b_target = output_batch[:,:,1].reshape(-1), b_target.reshape(-1)\n",
    "                attention_mask = attention_mask.cpu().numpy().reshape(-1)\n",
    "                output_batch = output_batch[attention_mask==1]\n",
    "                b_target = b_target[attention_mask==1]\n",
    "                try:\n",
    "                    acc = metrics.accuracy_score(b_target, (output_batch >= 0.5).astype(int))\n",
    "                    auc = metrics.roc_auc_score(b_target, output_batch)\n",
    "                    train_auc.update(auc, b_target.shape[0])\n",
    "                    \n",
    "                except:\n",
    "                    auc, acc = None, None\n",
    "                    pass\n",
    "\n",
    "                if print_step > 0 and i % print_step == 0:\n",
    "                    print(f'+++ [{msg}] Loss: {loss.item()} AUC: {auc} ACC: {acc}')\n",
    "#                     pdb.set_trace()\n",
    "                    \n",
    "        if not self.params.is_test:\n",
    "            print(f'>>> [{msg}] TOTAL AUC: {train_auc.avg}')\n",
    "            \n",
    "    def val_step(self, val_loader, print_step=300, msg='Valid'):\n",
    "        \n",
    "        self.model.eval()\n",
    "        val_auc = AverageMeter()\n",
    "        for i, databatch in enumerate(val_loader):\n",
    "            \n",
    "            # Move to device\n",
    "            input_batch = ()\n",
    "            for feature in databatch:\n",
    "                input_batch += (feature.to(device) if self.params.cuda else feature, )\n",
    "            \n",
    "            # Convert to dict-type\n",
    "            enc_batch, b_target = self.get_dict(input_batch)\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "            # FW model\n",
    "            output_batch = self.model(enc_batch).squeeze(-1)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                attention_mask = enc_batch['attention_mask']\n",
    "                attention_mask = attention_mask.cpu().numpy().reshape(-1)\n",
    "            \n",
    "            if self.params.cuda:\n",
    "                b_target = b_target.cpu().numpy()\n",
    "                output_batch = output_batch.detach().cpu().numpy()\n",
    "            else:\n",
    "                b_target = b_target.numpy()\n",
    "                output_batch = output_batch.detach().numpy()\n",
    "                \n",
    "            output_batch, b_target = output_batch[:,:,1].reshape(-1), b_target.reshape(-1)\n",
    "            output_batch = output_batch[attention_mask==1]\n",
    "            b_target = b_target[attention_mask==1]\n",
    "            \n",
    "            try:\n",
    "                acc = metrics.accuracy_score(b_target, (output_batch >= 0.5).astype(int))\n",
    "                auc = metrics.roc_auc_score(b_target, output_batch)\n",
    "                val_auc.update(auc, b_target.shape[0])\n",
    "            except:\n",
    "                auc, acc = None, None\n",
    "                pass\n",
    "            \n",
    "            if print_step > 0 and i % print_step == 0:\n",
    "                print(f'- [{msg}] AUC: {auc} ACC: {acc}')\n",
    "        \n",
    "        print(f'>>> [{msg}] TOTAL AUC: {val_auc.avg}')\n",
    "    \n",
    "    def val(self, val_batch):\n",
    "        \n",
    "        data_size, val_update = self.dataset.val_batch(val_batch)\n",
    "        print(f'[Valid] num_users: {data_size}')\n",
    "        \n",
    "        val_loader = self.get_dataloader(self.params.batch_size, shuffle=False)\n",
    "        self.val_step(val_loader, print_step=100)\n",
    "        \n",
    "        if self.params.is_update_valid:\n",
    "            print('--> push valid to storage')\n",
    "            self.dataset.late_update(val_update)\n",
    "\n",
    "    def train(self, data_batch):\n",
    "        \n",
    "        train_size, train_update = self.dataset.set_batch(data_batch)     \n",
    "        print(f'[Train] Num-cases: {train_size}')\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "        train_loader = self.get_dataloader(self.params.batch_size)\n",
    "        for epoch in range(self.params.n_epoch):\n",
    "            print(f'Epoch: {epoch}')\n",
    "            self.train_step(train_loader, print_step=10)    \n",
    "            \n",
    "        if self.params.is_update_train:\n",
    "            print('--> push train to storage')\n",
    "            self.dataset.late_update(train_update)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09b9a9ab-fc3e-4754-b7a7-1306e7ad3681",
    "_uuid": "fecc0823-9724-4461-b981-b9f77072f0af"
   },
   "source": [
    "# Training all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mini_chunks(data_chunk, csize=int(1e4)):\n",
    "    data_chunk = data_chunk.sort_values(by ='timestamp')\n",
    "    for i in range(0, int(data_chunk.shape[0]), csize):\n",
    "        yield data_chunk.iloc[i:i+csize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test(test_df):\n",
    "    indice = list(test_df.loc[~test_df['prior_group_answers_correct'].isnull()].index) \n",
    "    for i in range(len(indice)-1):\n",
    "        yield test_df.iloc[indice[i]:indice[i+1]]\n",
    "        \n",
    "    yield test_df.iloc[indice[i+1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "params.load_state = False\n",
    "params.n_epoch = 1\n",
    "params.n_chunks = 1000\n",
    "# save_part = None\n",
    "if params.load_state:\n",
    "    print(f'LOADING ALL DATASET ...')\n",
    "    mydata = LectureData(params, questions.copy(), lectures.copy()) \n",
    "    trainer = Trainer(mydata, params)\n",
    "        \n",
    "    print('LOADING PRETRAINED MODEL ...')\n",
    "    trainer.load_model(f'{params.save_dir}/model_latest.pth')\n",
    "    \n",
    "else:\n",
    "    print(f'STARTING TRAINING FROM SCRATCH ...')\n",
    "    mydata = None\n",
    "    trainer = None\n",
    "    \n",
    "    if trainer is None:\n",
    "        mydata = LectureData(params, questions.copy(), lectures.copy())  \n",
    "        trainer = Trainer(mydata, params)\n",
    "        \n",
    "start = time.time()\n",
    "for n, train_part in enumerate(chunks):\n",
    "    print(f'\\n***Training chunk-{n}:')\n",
    "    \n",
    "#     mini_chunks = gen_mini_chunks(train_part)\n",
    "#     for train_part in mini_chunks:\n",
    "            \n",
    "    rest_part, valid_part = split_data(train_part, n_tail=6) # 6\n",
    "    stat_part, train_part = split_data(rest_part, n_tail=100) # 32: goood\n",
    "    \n",
    "    valid_part = valid_part.sort_values(by ='timestamp')\n",
    "    train_part = train_part.sort_values(by ='timestamp')\n",
    "\n",
    "    print(f'\\nStat: {stat_part.shape} / Train: {train_part.shape} / Valid: {valid_part.shape}')\n",
    "    trainer.incre_update(stat_part, train_part, valid_part)\n",
    "\n",
    "    if True:\n",
    "        test_generator = gen_test(test_sample)\n",
    "        pred = None\n",
    "        for test_part in test_generator: \n",
    "            try:\n",
    "                prior_correct = eval(test_part['prior_group_answers_correct'].iloc[0])\n",
    "                prior_correct = [a for a in prior_correct if a != -1]\n",
    "                if pred is not None:\n",
    "                    assert len(prior_correct) == len(pred)\n",
    "                    auc = metrics.roc_auc_score(prior_correct, pred)\n",
    "                    print(f'>>> [TESTING] AUC: {auc}')\n",
    "            except:\n",
    "                prior_correct = []\n",
    "            s1 = time.time()\n",
    "            pred = trainer.infer(test_part)\n",
    "#             trainer.finetune_batch()\n",
    "            print(f'Testing batch: {time.time() - s1}')\n",
    "\n",
    "    if n >= params.n_chunks:\n",
    "        break\n",
    "\n",
    "    print(f'Time elapsed: {time.time() - start}')\n",
    "\n",
    "print(f'Saving all model + data ...')\n",
    "trainer.save_model(params.save_dir)\n",
    "trainer.save_data(params.save_dir)\n",
    "\n",
    "print(f'Training finished in {time.time() - start} seconds')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2ce63614-a288-4be0-ae66-49df369340ca",
    "_uuid": "7bbfc78f-7707-4d61-9bf1-84dc7228a516"
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "# You can only call make_env() once, so don't lose it!\n",
    "env = riiideducation.make_env()\n",
    "\n",
    "# You can only iterate through a result from `env.iter_test()` once\n",
    "# so be careful not to lose it once you start iterating.\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Submission\n",
    "################################\n",
    "\n",
    "print(f'Start testing ....')\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    # do prediction\n",
    "    pred = trainer.infer(test_df)\n",
    "\n",
    "    # fill all value first\n",
    "    test_df['answered_correctly'] = 0.5\n",
    "    \n",
    "    # Only fill question-type\n",
    "    test_df.loc[test_df['content_type_id'] == 0, 'answered_correctly'] = pred\n",
    "\n",
    "    # submit prediction    \n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n",
    "    \n",
    "    trainer.finetune_batch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
